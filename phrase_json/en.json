{
  "ASF_SB_1": "# asf_search Basics\n\n## Overview\n\nasf_search is a Python module for performing searches of the ASF catalog. In addition, it offers baseline functionality and download support. It is available through PyPi and Conda.\n\n\timport asf_search as asf\n\n\tresults = asf.granule_search(['ALPSRS279162400', 'ALPSRS279162200'])\n\tprint(results)\n\n\twkt = 'POLYGON((-135.7 58.2,-136.6 58.1,-135.8 56.9,-134.6 56.1,-134.9 58.0,-135.7 58.2))'\n\tresults = asf.geo_search(platform=[asf.PLATFORM.SENTINEL1], intersectsWith=wkt, maxResults=10)\n\tprint(results)\n\nFor an introductory walkthrough of asf_search, see the [Jupyter Notebooks](https://github.com/asfadmin/Discovery-asf_search/tree/master/examples).\n\n## Installation\nIn order to easily manage dependencies, we recommend using dedicated project environments via [Anaconda/Miniconda](https://docs.conda.io/projects/conda/en/latest/user-guide/install/index.html) or [Python virtual environments](https://docs.python.org/3/tutorial/venv.html).\n\nasf_search can be installed into a conda environment with\n\n\tconda install -c conda-forge asf_search\n\nor into a virtual environment with\n\n\tpython -m pip install asf_search\n\n## Usage\nProgrammatically searching for ASF data is made simple with asf_search. Several search functions are provided. Each search function returns an ```ASFSearchResults``` object:\n\n- ```geo_search()``` Find product info over an area of interest using a WKT string\n- ```granule_search()``` Find product info using a list of scene names\n- ```product_search()``` Find product info using a list of product IDs\n- ```stack_from_id()``` Find a baseline stack of products using a reference scene\n- If the above search approaches do not meet your search needs, ```search()``` supports all available keywords:\n\t- ```search()``` Find product info using any combination of search parameters\n- Additionally, numerous constants are provided to ease the search process. Currently, we provide constants for beam mode, flight direction, instrument, platform, polarization, and product type. You can see the full [list of constants here](https://github.com/asfadmin/Discovery-asf_search/tree/master/asf_search/constants).\n\nAdditionally, asf_search supports downloading data, both from search results as provided by the above search functions, and directly on product URLs. An authenticated session is generally required. More information on available authentication methods can be found [here](https://requests.readthedocs.io/en/latest/user/authentication/). You may also authenticate using an ```ASFSession``` object and one of the following authentication methods. ```ASFSession``` is a subclass of ```Session```.\n\n- ```auth_with_creds('user', 'pass)```\n- ```auth_with_token('EDL token')```\n- ```auth_with_cookiejar(http.cookiejar)```\n\nIf not using .netrc credentials, that session should be passed to whichever download method is being called, can be re-used, and is thread safe.\n\nExample using .netrc:\n\n\tresults = ....\n\tresults.download(path='....')\n\nExample with manual authentication:\n\n\tresults = asf_search.granule_search([...])\n\tsession = asf_search.ASFSession().auth_with_creds('user', 'pass')\n\tresults.download(path='/Users/SARGuru/data', session=session)\n\nAlternately, asf_search supports downloading an arbitrary list of URLs. All of the available authentication methods are supported:\n\n\turls = [...]\n\tasf_search.download_urls(urls=urls, path='/Users/SARGuru/data', session=ASFSession().auth_with_token('EDL token'))\n\nAlso note that ```ASFSearchResults.download()``` and the generic ```download_urls()``` function both accept a ```processes``` parameter which allows for parallel downloads.\n\nFurther examples of all of the above can be found in this [sample script](https://github.com/asfadmin/Discovery-asf_search/blob/master/examples/hello_world.py).",
  "ASFPRODUCT_1": "# ASFProduct\n\n## Description\n\nThis class describes a single product from the ASF archive. The class provides metadata, as well as several helpful methods for interacting with the product.\n\n***\n\n## Attributes\n- `properties` _(dict)_: Provides product metadata such as Beam Mode, Start Time, etc.\n- `geometry` _(dict)_: Describes the product's physical extents as a geojson snippet.\n- `baseline` _dict_: The product's baseline related fields, if available in CMR.\n- `umm` _(dict)_: the raw umm json response from CMR used to populate `properties`, `geometry`, `baseline`, and `meta`.\n- `meta` _(dict)_: the metadata json returned from CMR.\n<!-- netrc\nhow to build netrc file, link\nOR auth with these options instead -->\n\n***\n\n## Methods\n\n### <span style=\"color: #236192; font-size: 20px;\">geojson()</span>\n\n`ASFProduct.__str__()` utilizes this method for serialization via `json.dumps()`\n\n**args:**\nNone\n\n**returns:**\n\n- `dict` describing the product as a geojson snippet.\n\n***\n\n### <span style=\"color: #236192; font-size: 20px;\">download(path, _filename=None, session=None_)</span>\n\nDownloads this product to the specified path and optional filename.\n\n**args:**\n\n- path: The directory into which this product should be downloaded.\n- filename _(optional)_: Filename to use instead of the original filename of this product.\n- session _(optional)_: The session to use, in most cases should be authenticated beforehand. If no session is provided, a blank (unauthenticated) session will be used.\n- fileType _(optional)_: Used to download Burst XML metadata. Specify ````fileType=asf.FileDownloadType.ADDITIONAL_FILES```` to download the XML metadata. To download both .tiff and .xml files for bursts, use ````asf.FileDownloadType.ALL_FILES````\n\t- Example: ````burst_results.download(session=session, path=\"./\", fileType=asf.FileDownloadType.ADDITIONAL_FILES)````\n\t- Note: The Burst XML Metadata is a virtually generated file, and therefore does not have its own unique filename. The XML Metadata can only be found via the burst scene name.\n\n**returns:**\nNone\n\n***\n\n### <span style=\"color: #236192; font-size: 20px;\">stack()</span>\n\nBuilds a baseline stack using this product as a reference\n\n**args:**\n\n- cmr_provider _(optional)_: Custom provider name to constrain CMR results to, for more info on how this is used, see [CMR documentation](https://cmr.earthdata.nasa.gov/search/site/docs/search/api.html#c-provider)\n- session _(optional)_: A Session to be used when performing the search. For most uses, can be ignored. Used when searching for a dataset, provider, etc. that requires authentication. See [ASFSession](/asf_search/ASFSession) for more details.\n- host _(optional)_: SearchAPI host, defaults to Production SearchAPI. This option is intended for dev/test purposes and can generally be ignored.\n\n**returns:**\n\n- ```ASFSearchResults``` representation of the stack, with the addition of baseline values (temporal, perpendicular) attached to each `ASFProduct`\n\n***\n\n### <span style=\"color: #236192; font-size: 20px;\">get_stack_opts()</span>\n\nBuilds search options that describe an InSAR stack based on this product. Similar to `stack()` but doesn't perform the search, simply returns ```ASFSearchOptions``` which can be inspected or adjusted and then passed to various search functions.\n\n**args:**\nNone\n\n**returns:**\n\n- ```ASFSearchOptions``` object\n\n***\n\n### <span style=\"color: #236192; font-size: 20px;\">centroid()</span>\n\nDetermines the centroid of a product.\n\n**args:**\nNone\n\n**returns:**\n\n- ```shapely.geometry.point.Point``` object describing the centroid of the product\n\n<!-- Will have more than geojson export; add this when other output options available -->\n\n### <span style=\"color: #236192; font-size: 20px;\">remotezip()</span>\n\nReturns a configured RemoteZip object, which allows downloading selected parts of a product's zip archive.\nFor more information on how to use remotezip with asf-search, see the `Downloading Single Products` section of [the example jupyter notebook](https://github.com/asfadmin/Discovery-asf_search/blob/master/examples/5-Download.ipynb). For more information on the open-source remotezip package, check out <a target=\"_blank\" href=\"https://github.com/gtsystem/python-remotezip\">the remotezip project repo</a>.\n\n**args:**\n\n- `session` _ASFSession_: An authenticated _ASFSession_ object that will be used to download the product\n\n**returns:**\n\n- ```remotezip.RemoteZip``` object authenticated with the passed _ASFSession_ object\n",
  "ASFSESSION_1": "# ASFSession\n\n## Description\n\nThis class extends `requests.session` to provide convenient ASF-specific authorization options. `ASFSession` is a subclass of `Session`. More information can be found [here](https://docs.python-requests.org/en/master/user/authentication/)\n\n***\n\n## Methods\n\n### <span style=\"color: #236192; font-size: 20px;\">auth_with_creds()</span>\n\nAuthenticates the session (self) using [Earthdata Login](https://urs.earthdata.nasa.gov/) username/password credentials.\n\n**args:**\n\n- username: [Earthdata Login](https://urs.earthdata.nasa.gov/) username\n- password: [Earthdata Login](https://urs.earthdata.nasa.gov/) password\n\n**returns:**\n\n- returns self for convenience\n\n***\n\n### <span style=\"color: #236192; font-size: 20px;\">auth_with_token()</span>\n\nAuthenticates the session (self) using an Earthdata Login `Authorization: Bearer` token.\n\n**args:**\n\n- token: Earthdata Login token for authenticated downloads, see [Earthdata Login Tokens](https://urs.earthdata.nasa.gov/user_tokens)\n\n**returns:**\n\n- returns self for convenience\n\n***\n\n### <span style=\"color: #236192; font-size: 20px;\">auth_with_cookiejar()</span>\n\nAuthenticates the session (self) using a pre-existing cookiejar.\n\n**args:**\n\n- cookies: An `http.cookiejar` compatible object\n\n**returns:**\n\n- returns self for convenience\n",
  "ASFSOPS_1": "# ASF Search Options\n\n## Description\n\nThis class describes a set of search parameters. While it is not required to use this class when constructing a search, it can be useful, as it provides some degree of immediate parameter validation, as well as a convenient way to manipulate and handle search options in general.\n\nSpecific search parameters are handled as object attributes. Attempting to add an attribute that is not supported will raise a KeyError. Attempting to delete an attribute will result in it being set to None. Search parameters can be set via kwargs at object instantion, or directly on an existing object using the normal mechanisms.\n\nConverting to a `dict` will only include search options which have actually been set to a usable value. That is, any options set to `None` will be ignored.\n\n***\n\n## Attributes\n- maxResults\n- absoluteBurstID\n- absoluteOrbit\n- asfFrame\n- beamMode\n- provider\n- collectionName\n- maxDoppler\n- minDoppler\n- maxFaradayRotation\n- minFaradayRotation\n- flightDirection\n- flightLine\n- fullBurstID\n- frame\n- granule_list\n- product_list\n- intersectsWith\n- lookDirection\n- offNadirAngle\n- operaBurstID\n- platform\n- polarization\n- processingLevel\n- relativeBurstID\n- relativeOrbit\n- processingDate\n- start\n- end\n- season\n- groupID\n- insarStackId\n- instrument\n- session\n\n***\n\n## Methods\n\n_ASFSearchOptions does not provide any methods intended for direct use, instead relying on a handful of dunders for the desired behavior. For clarity, these are included below._\n\n### <span style=\"color: #236192; font-size: 20px;\">__init__()</span>\n\nEstablishes the various attributes described above and processes any kwargs into them.\n\n**args:**\n\n- _**kwargs_, limited to names listed as attributes above. Anything else will raise a `KeyError`\n\n**returns:**\nNone\n\n***\n\n### <span style=\"color: #236192; font-size: 20px;\">__setattr__()</span>\n\nSets the attribute named by `key` to the specified `value` after passing it through an appropriate validator function.\n\nValues of `None` are allowed as a way to un-set the attribute. Attempting to set a `key` not listed in the above attribute list will raise a `KeyError`\n\n**args:**\n\n- key: the name of the attribute to set\n- value: the value to which the named attribute should be set\n\n**returns:**\nNone\n\n***\n\n### <span style=\"color: #236192; font-size: 20px;\">__delattr__()</span>\n\nClears an attribute names by `item` by way of setting it to `None`\n\n**args:**\n\n- item: the name of the attribute to be cleared\n\n**returns:**\nNone\n\n***\n\n### <span style=\"color: #236192; font-size: 20px;\">__iter__()</span>\n\nUsed when converting the ASFSearchOptions object to more fundamental objects, such as `dict`\n\nOnly includes attributes that are not `None`.\n\n**args:**\nNone\n\n**yields:**\n\n- (key, value) pairs for each of the above attributes that are not `None`\n\n***\n\n",
  "ASFSS_1": "# ASFSearchResults\n\n## Description\n\nThis class describes a set of search results from the ASF archive. The class provides a convenient way to manage and examine search results, as well as export and download functionality.\n\n***\n\n## Attributes\n- `searchOptions` _(ASFSearchOptions)_: The search options used to generate this set of results. May be `None` in some cases.\n- `searchComplete` _(bool)_: Flag signifying `asf_search.search()` sucessfully completed gathering results from CMR. \n***\n\n## Methods\n\n### <span style=\"color: #236192; font-size: 20px;\">download()</span>\n\nIterates over each ```ASFProduct``` and downloads them to the specified path.\n\n**args:**\n\n- path: The directory into which the products should be downloaded.\n- session: The session to use, in most cases should be authenticated beforehand.\n- processes: Number of download processes to use. Defaults to 1 (i.e. sequential download)\n- fileType _(optional)_: Used to download Burst XML metadata. Specify ````fileType=asf.FileDownloadType.ADDITIONAL_FILES```` to download the XML metadata. To download both .tiff and .xml files for bursts, use ````asf.FileDownloadType.ALL_FILES````\n\t- Example: ````burst_results.download(session=session, path=\"./\", fileType=asf.FileDownloadType.ADDITIONAL_FILES)````\n\t- Note: The Burst XML Metadata is a virtually generated file, and therefore does not have its own unique filename. The XML Metadata can only be found via the burst scene name.\n\n**returns:** None\n\n***\n\n### <span style=\"color: #236192; font-size: 20px;\">geojson()</span>\n\n`ASFSearchResults.__str__()` utilizes this method for serialization via `json.dumps()`\n\n**args:** None\n\n**returns:**\n\n- `dict` describing the search results as a geojson object.\n\n### <span style=\"color: #236192; font-size: 20px;\">csv()</span>\n\nCreates a csv formatted string generator from the results\n\n**args:** None\n\n**returns:**\n\n- A csv formatted string generator\n\n### <span style=\"color: #236192; font-size: 20px;\">kml()</span>\n\nCreates a kml formatted string generator from the results\n\n**args:** None\n\n**returns:**\n\n- A kml formatted string generator\n\n### <span style=\"color: #236192; font-size: 20px;\">metalink()</span>\n\nCreates a metalink formatted string generator from the results\n\n**args:** None\n\n**returns:**\n\n- A metalink formatted string generator\n\n### <span style=\"color: #236192; font-size: 20px;\">raise_if_incomplete()</span>\n\nUse to check if results returned from `asf_search.search()` are incomplete (this can happen\nif an error occurs while querying CMR)\n\n**args:** None\n\n**raises:**\n\n- Raises an `asf_search.exceptions.ASFSearchError` if the results are incomplete\n",
  "BASELINE_1": "#Baseline Search Type\n\n## What is Baseline?\nBaseline uses information from two synthetic aperture radar (SAR) images of the same target area acquired at different times (temporal baseline) and from slightly different satellite orbit positions (perpendicular baseline). The Vertex baseline tool helps you identify and select scene pairs that are appropriate for Interferometric SAR (InSAR) processing. It provides visualization of perpendicular and temporal baseline data, and allows you to easily change the reference scene used in any stack.\n\n## How to use Vertex Baseline Tool\nVisit **[ASF's Vertex](https://search.asf.alaska.edu)** to begin using the Baseline tool.\n![type:video](https://www.youtube.com/embed/Xp5bgvi2pEM)\n\n### **Beginning your Baseline Search**\n\n- If you do not have a particular reference scene chosen, you can search for scenes using the geographic or list search. The center column will have a button under the metadata titled ***Baseline Tool*** for any scenes that are eligible. You may click this button to be directed to a Baseline search. The Baseline search will use the chosen scene as the reference scene.\n\n- If you do have a particular reference scene chosen, you can select ***Baseline*** from the Search Type dropdown list. You may enter your reference scene and hit ***Search***.\n\n### **Interacting with Baseline Search Results**\nWhile in Baseline Search type, you will notice many familiar controls in the results panel. The scenes are shown in the left column. The perpendicular and temporal baselines are listed next to each scene. The center column lists the metadata for the selected scene, and includes the **Set as Reference** button, which allows you to set any scene in the stack as the reference scene. The Baseline Chart is shown in the right column.\n\n**Result Panel Controls**\n\n- At the top left of the results panel, you will see the number of scenes listed.\n- **Zoom** will *Zoom to results* magnifying the map area of the Earth where the scenes are located.\n- **Queue** will *Add all results to Downloads* allowing you to add all scenes to the download queue.\n- **On Demand** will allow you to *Add all results to On Demand queue* to do custom processing on the scenes. To learn more click [here](https://hyp3-docs.asf.alaska.edu/using/vertex/). You may also choose to *Create Subscription*. More details about subscriptions can be found [here](https://hyp3-docs.asf.alaska.edu/using/subscriptions/).\n- **Export** will allow you to *Download data/metadata* for all scenes in the stack.\n- In the left column, **Queue** will *Add scene files to downloads* for the selected scene only.\n- Under the metadata in the center column, **Set as Reference** will allow you to set any scene in the stack as the reference scene. When you select this, both the chart and the baseline values will be updated automatically.\n\n**Chart Controls**\n\n- The dots on the chart represent individual scenes. Hovering over them will list their temporal and perpendicular values. You may also click on any point to select that scene. The metadata in the center column will be updated.\n- Located above the chart, there are labels and corresponding colors. These indicate how the reference scene, selected scene, and any scenes in your download queue are displayed on the chart. Some datasets include a shaded area which indicates the critical baseline.\n- You may zoom and pan the chart.\n\n#### Baseline Criteria\n\n- You may click **Baseline Criteria...** above the chart for additional options.\n\t- You can adjust the sliders to change the perpendicular and temporal values that you wish to be included in your results.\n\t- You can enter a start and end date.\n\t- Changing any criteria will automatically update the list of scenes and the chart.\n\n## Next Steps\nOnce you are satisfied with your result set, you can use the download queue to manage and download baseline results. More information about the download queue can be found in the [Vertex Getting Started User Guide](/vertex/manual).\n\nIf you wish to create interferograms, custom processing is now available through Vertex. Details are available in the On Demand Queue section of the [Vertex Getting Started User Guide](/vertex/manual). You can find more information about creating interferograms with ASF's custom processing through the [HyP3 documentation](https://hyp3.asf.alaska.edu/about).\n",
  "CHANGELOG_1": "# What's New\n\n\n## Vertex is Now Multilingual!\n\nVertex now supports English and Spanish. If your browser language is set to Spanish, Vertex will default to Spanish. You can also select your preferred language from the top menu. More information can be found [here](/vertex/manual/#language-options).\n\n## Area of Interest: Search for a Location\nYou can now search for a location name as your area of interest. The *Search for a Location* field can be found by opening the Area of Interest window. More information can be found [here](/vertex/manual/#area-of-interest-options).\n\n\n## New On Demand Option\n\nSentinel-1 RTCs may now be processed at 10-meter pixel spacing. More information can be found [here](https://hyp3-docs.asf.alaska.edu/guides/rtc_product_guide/#pixel-spacing). More about the On Demand queue can be found [here](/vertex/manual/#on-demand-queue).\n\n\n## Enhanced Downloads for Google Chrome\n\nEnhanced download queue functionality is available on Google Chrome browser. Included are download progress indicators, and the option to download all files in the queue. Download all will download 3 files concurrently until all files in the queue have been downloaded. More information can be found [here](https://docs.asf.alaska.edu/vertex/manual/#google-chrome-browser).\n\n",
  "CHANGELOG_2": "# What's New\n\n## Dataset keyword\nThe new \"dataset\" keyword is the preferred alternative for platform searches. It allows results from multiple platforms at once. More information can be found [here](/api/keywords/#dataset-parameters).\n\n## New Python module for performing searches\nasf_search is a Python module for performing searches of the ASF catalog. In addition, it offers baseline functionality and download support. It is available through PyPi and Conda. More information can be found [here](/asf_search/basics).\n\n## Multiple Endpoints Available\n\nIn addition to the Search endpoint, we have multiple endpoints available for all of your Search API needs. Below is a brief overview of what's available. More details on these endpoints and how to use them can be found on the [Keywords page](/api/keywords).\n\n\n**Baseline Endpoint**\n\nThis endpoint can be used to search for baseline data using specific reference scenes.\n\n**WKT Endpoints**\n\nThe WKT validation endpoint will validate and repair a WKT input. The GeoSpatial Files to WKT endpoint will accept a POST request with files attached. It will return the parsed WKT from the file, as well as the repaired wrapped and unwrapped WKT.\n\n**Date Parser Endpoint**\n\nThis endpoint can be used to check how dates are parsed by the Search API.\n\n**Mission List Endpoint**\n\nThis endpoint lists all missions (also known as campaigns or collections) for all datasets.\n\n**Health Endpoint**\n\nThis endpoint is used to check the Search API health. It also provides information on CMR health.\n\n## Preferred Search API Output Format\n\nGeoJSON is the preferred Search API output format. You can specify the output format with keyword \"output\". If you find a required field that is not included in GeoJSON output, please contact ASF using the info below or reach the team directly at <uaf-asf-discovery@alaska.edu>.",
  "COOKBOOK_1": "# Search API Tips & Tricks\n\nThis is a collection of some tips & tricks for the Search API!\n\n## New Python module for performing searches\nasf_search is a Python module for performing searches of the ASF catalog. In addition, it offers baseline functionality and download support. It is available through PyPi and Conda. More information can be found [here](/asf_search/basics).\n\n## Rate Limitation on Search Endpoint\nThere has been a rate limitation instituted on the [search endpoint](/api/keywords/#search-endpoint). The rate limitation is per IP and is currently 250 queries per minute. Upon hitting the limit, further queries will yield a HTTP 429 with an error message. Check to see if your queries are returning a small number of results. If so, you can refine your parameters to combine result sets into larger groups and then post-process those results locally. For instance, instead of searching on a small area of interest with an individual query for each day, select a larger date range in order to create a single query, then split the results apart after they have been retrieved.\n\n## Vertex Copy/Paste Search API URL\nHave you have completed a geo search in Vertex, that you'd like to replicate in a Search API query? Click the Down Arrow under the Max Results. Choose \"API URL...\".\n\nHere you can see the Search API URL you would use to replicate the search. You may change the maxResults and output format. Once you are satisfied, click the copy icon. Now you can paste the query into a browser or command line interface to execute it.\n\n## Find the Product_List Value in Vertex\nThe product/file name is listed in Vertex Search Results, under the Files detail column. You can click the Copy icon to copy the File ID. You can also copy all File IDs from your Download Queue in Vertex. Once you have your desired list of files, you can find them via the Search API using the product_list keyword.\n\n## Search Results Can Become Search Area\nYou can turn your search results into a search area. First, export your search results as GeoJSON or KML output format. Next, import your file into Vertex geo search. Vertex will extract the AOI from your file. If desired, you can add filters and can save your search filters or the search itself.\n\n## Verify Your Query is Returning the Correct Number of Results\nWould you like to verify that your query has returned the correct number of results? Change your output to \"output=count\" to verify. If the count does not match, consider narrowing your search by using more keywords, or by using keyword “maxResults” to limit it. You may also try shortening the date range to split your search into a series of smaller searches.",
  "DERIVED_DATASETS_1": "# Derived Datasets Search Type\n\n## What are Derived Datasets?\n\nDerived datasets are higher-level datasets created using SAR data. The datasets listed below are ASF's collection.\n\n### Global Seasonal Sentinel-1 Interferometric Coherence & Backscatter Dataset\n\nThis dataset is the first-of-its-kind spatial representation of multi-seasonal, global SAR repeat-pass interferometric coherence and backscatter signatures. Global coverage comprises all land masses and ice sheets from 82 degrees northern to 78 degrees southern latitude. The dataset is derived from high-resolution multi-temporal repeat-pass interferometric processing of about 205,000 Sentinel-1 Single-Look-Complex (SLC) data acquired in Interferometric Wide-Swath mode (Sentinel-1 IW mode) from 1-Dec-2019 to 30-Nov-2020. Further information can be found [here](https://asf.alaska.edu/datasets/derived/global-seasonal-sentinel-1-interferometric-coherence-and-backscatter-dataset/).\n\n### Global Ice Sheet Mapping Observatory (GISMO)\n\nThe Global Ice-Sheet Mapping Observatory (GISMO) spaceborne radar system is part of the NASA Instrument Incubator Project (IIP). GISMO has a specific focus in measuring the surface topography of ice sheets, ice-sheet thickness, and in uncovering physical properties of the glacier bed using SAR. It utilized VHF and P-band interferometric radars and tested different methods of clutter rejection. GISMO achieved mapping the physical properties of a glacier bed through up to 5 km of ice. The GISMO project documented flight lines over the Greenland ice sheet in 2006, 2007, and 2008. Further information can be found [here](https://asf.alaska.edu/data-sets/derived-data-sets/global-ice-sheet-mapping-orbiter-gismo/).\n\n### Glacier Speed\n\nThis dataset was produced by Evan Burgess and colleagues at the University of Utah and the University of Alaska Fairbanks using ALOS PALSAR data. It reveals complex patterns of glacier flow throughout Alaska. The speed data are available for download in formats designed both for scientists and educators. Surface velocities are available for 47,880 km^2 of glacier ice, which includes almost all of the state’s major glaciers. Detailed information on its production is available in [Burgess et al., Nature Communications, 2013](https://www.nature.com/articles/ncomms3146). Further information can be found [here](https://asf.alaska.edu/data-sets/derived-data-sets/glacier-speed/).\n\n### International Polar Year\n\nInternational Polar Year (IPY) is a collaborative research event focused on the Arctic and Antarctic. IPY 2007-2009 focused on collaborative research and extensively explored the complex relationships between the Arctic and Antarctic. Over 60 countries and thousands of researchers participated, investigating more than 200 projects. Topics include Arctic and Antarctic relationships with geophysical elements, oceans and sea ice, Earth’s atmosphere, space, and human relations. ASF hosts an archive of the IPY project titled the Global Inter-agency IPY Polar Snapshot Year (GIIPSY). GIIPSY’s objective was to obtain high-definition satellite snapshots of the polar regions during 2007-2008. Further information can be found [here](https://asf.alaska.edu/data-sets/sar-data-sets/international-polar-year-2007-2008/).\n\n\n### Radarsat-1 Antarctic Mapping Project (RAMP)\n\nThe RADARSAT-1 Antarctic Mapping Project (RAMP) is composed of two main missions, the first Antarctic Mapping Mission (AMM-1) and the Modified Antarctic Mapping Mission (MAMM). AMM-1 started on September 9, 1997 and was completed on October 20, 1997. Its goals were to acquire a complete map of Antarctica and better understand the relationships between the southernmost continent’s environmental elements. MAMM started on September 3, 2000 and was completed on November 17, 2000. It planned to remap Antarctica and measure ice velocity data using interferometric analysis and data from AMM-1. Further information can be found [here](https://asf.alaska.edu/data-sets/derived-data-sets/radarsat-antarctic-mapping-project-ramp/).\n\n\n### Sea Ice MEaSUREs\n\nSea-ice imagery and data products are supported under NASA’s Making Earth System data records for Use in Research Environments (MEaSUREs) program. Arctic and Southern Ocean imagery, data, and data products are available at no cost to approved users from the ASF DAAC. These include over 11 years of RADARSAT-1 three-day radar snapshots of Arctic and Southern Ocean sea ice, and original SAR images. RADARSAT-1 data have been processed to construct a near decadal record of small-scale ice motion of the Arctic and Southern Oceans, a record of ice motion of the northern Bering Sea, and monthly high-resolution image mosaics of the Arctic Ocean. Further information can be found [here](https://asf.alaska.edu/data-sets/derived-data-sets/sea-ice-measures/).\n\n### Wetlands MEaSUREs\n\nThe inundated wetlands Earth System Data Record (ESDR) consists of two primary components. First, fine-resolution maps of wetland extent, vegetation type, and seasonal inundation dynamics, derived from SAR for regional and continental-scale areas covering crucial wetlands systems. Second, global coarse-resolution time series mappings of inundated area fraction at ~25 km resolution derived from multiple satellite remote sensing observations including passive and active microwave sensors and optical data sets optimized for inundation detection. These datasets are provided on a bi-monthly basis for 1992-1999 and daily for 2000 onward. Annual summary products and a daily near real time (NRT) dataset with 2-3 day latency are also provided. Further information can be found [here](https://asf.alaska.edu/data-sets/derived-data-sets/wetlands-measures/).\n",
  "DOWNLOADING_1": "#Downloading\n\n## Session Authentication\n\nasf_search supports downloading data, both from search results as provided by the search functions, and directly on product URLs. An authenticated session is generally required. asf_search uses ```Requests```. Using .netrc credentials is the preferred method for authentication. More information on .netrc authentication can be found [here](https://requests.readthedocs.io/en/latest/user/authentication/#netrc-authentication).\n\nExample using .netrc:\n\n\tresults = ....\n\tresults.download(path='....')\n\nIf not using .netrc credentials, you may authenticate using an ```ASFSession``` object and one of the following authentication methods. ```ASFSession``` is a subclass of ```Session```. The session should be passed to whichever download method is being called, can be re-used, and is thread safe. \n\n- ```auth_with_creds('user', 'pass)```\n- ```auth_with_token('EDL token')```\n- ```auth_with_cookiejar(http.cookiejar)```\n\nExample with manual authentication:\n\n\tresults = asf_search.granule_search([...])\n\tsession = asf_search.ASFSession().auth_with_creds('user', 'pass')\n\tresults.download(path='/Users/SARGuru/data', session=session)\n\nasf_search also supports downloading an arbitrary list of URLs. All of the available authentication methods are supported:\n\n\turls = [...]\n\tasf_search.download_urls(urls=urls, path='/Users/SARGuru/data', session=ASFSession().auth_with_token('EDL token'))\n\nAlso note that ```ASFSearchResults.download()``` and the generic ```download_urls()``` function both accept a ```processes``` parameter which allows for parallel downloads.\n\n## Methods\n### <span style=\"color: #236192; font-size: 20px;\">download_urls()</span>\n\nDownloads all products from the specified URLs to the specified location.\n\n**args**\n\n- urls: List of URLs from which to download\n- path: Local path in which to save the product\n- session: The session to use, in most cases should be authenticated beforehand\n- processes: Number of download processes to use. Defaults to 1 (i.e. sequential download)\n\n### <span style=\"color: #236192; font-size: 20px;\">download_url()</span>\n\nDownloads a product from the specified URL to the specified location and (optional) filename.\n\n**args**\n\n- url: URL from which to download\n- path: Local path in which to save the product\n- filename: Optional filename to be used, extracted from the URL by default\n- session: The session to use, in most cases should be authenticated beforehand\n\n### <span style=\"color: #236192; font-size: 20px;\">remotezip()</span>\n\nConfigures and returns an authenticated ```remotezip.RemoteZip``` object, allowing downloading of\nspecific files from a given zip archive without downloading the entire archive.\n\n**args**\n\n- url: URL from which to download a zip archive\n- session: Authenticated ```ASFSession``` that RemoteZip will use to download from the zip product\n\n**returns:**\n\n- `remotezip.RemoteZip` object authenticated with the passed _ASFSession_ object\n\n## Export Formats\nasf_search provides multiple export formats, in addition to the default asf_search format. Available formats are: geojson, csv, metalink, kml, jsonlite, jsonlite2.\n\nExamples:\n\n\tresults = ....\n\twith open(\"search_results.csv\", \"w\") as f:\n\t\tf.writelines(results.csv())\n\n\tresults = ....\n\twith open(\"search_results_jsonlite.json\", \"w\") as f:\n\t\tf.writelines(results.jsonlite())\n\n",
  "EVENTS_SEARCH_1": "# Event Search Type\n\n## What is Event Search?\nEvent search harnesses the capabilities of SAR proccessing to monitor natural disasters. Currently supported hazards are volcanic eruptions and earthquakes.  Generated products include fully terrain corrected image time series, as well as interferometric SAR data over areas affected by natural disasters. To facilitate full automation, the processing flow is triggered automatically by existing hazard alert systems such as the USGS Earthquake Notification Service. Event monitoring through Vertex is based on technology developed within SARVIEWS through grant NNX12AQ38G. Visit the [Events (SARVIEWS) documentation](/datasets/events_about) for more information.\n\n## How to use Vertex Event Search\nVisit **[ASF's Vertex](https://search.asf.alaska.edu)** to begin using the Event search.\n\n### **Beginning your Event Search**\n\n- When you select **Event** search type, a search will be performed, and all available events will be displayed. As with other search types, there are filters available to limit or refine your search results.\n- Click **Event Search** to enter an event name or partial name. You may also select the desired event from the drop down list displayed when you click the field.\n- Under **Event Types**, you can choose which event types you wish to be displayed. Currently, there are Earthquake and Volcano events.\n- You may select a **Start Date** or **End Date**.\n- Click **Filters** for more options\n\t- You may toggle the **Active Events Only** switch to display only active events. The default is to display all events, including inactive events.\n\t- You may adjust the **Magnitude** slider to filter earthquakes by your desired magnitude range. *Note:* This filter applies only to earthquake events. If your search includes volcanoes, these will continue to be displayed in your search results.\n- Once you have selected your desired Filters, click **Search** to update your search results.\n\n#### **Product Filters**\n- **Path and Frame Filters** are available. You may enter a single path or frame, or a range.\n\t- Click **Clear** to clear the entered path and frame values.\n\t- Note that **Path and Frame** will filter the displayed products within each event.\n- Under **Product Type**, you may select one or more product types. This will filter the displayed products within each event.\n\n### **Interacting with Event Search Results**\nWhile in Event Search type, you will notice many familiar controls in the results panel. The events are shown in the left column. The Volcano and Earthquake icons note what type of event each result is. The center column lists the detail and metadata for the selected event. The Files for the selected event are shown in the right column.\n\n**Result Panel Controls**\n\n- At the top left of the results panel, you will see the number of events returned by your search.\n- **Zoom** will *Zoom to results* magnifying the map area of the Earth where the event is located.\n- **Queue** will *Add all results to Downloads* allowing you to add all event products to the download queue.\n\t- You may choose to add **All Event Products** or **Selected Event Products** to the download queue. You may select individual files in the right column.\n- **Export** will download the Bulk Download Script. This Python script allows you to download all products from the selected scene.\n- **On Demand** will allow you to *Add all results to On Demand queue* to do custom processing on the scenes. Depending on the types of files associated with the chosen event, you may be able to add RTC or InSAR jobs to your queue. To learn more click [here](https://hyp3-docs.asf.alaska.edu/using/vertex/).\n- **Copy** allows you to copy either the **Scene IDs** or the download **URLs**.\n\t- You may choose to copy either **All** Scene IDs or URLs, or only copy **Selected** Scene IDs or URLs. You may select individual files in the right column.\n- The Events column (left).\n\t- Each event has either an earthquake or a volcano icon to the left of it, to help you quickly identify the event type.\n\t- Click **Zoom to Event** to magnify the map area of the Earth where the event is located.\n- The Event Detail column (middle).\n\t- The event details are listed here. This includes the event processing start and stop time. For earthquakes, the magnitude and depth is also displayed.\n\t- You may **Copy** the Event ID.\n\t- Click **SARVIEWS Event** to be directed to the SARVIEWS page for your chosen event.\n\t- For earthquake events, the **USGS ID** is listed. For volcanoes, the **Smithsonian ID** is listed. Click the link to go to the USGS or Smithsonian event page.\n\t- Adjust the **Geographic Search Polygon Scale** slider as desired. The Area of Interest polygon will also update on the map.\n\t- Once you are happy with the **Geographic Search Polygon Scale**, click **Geographic** to launch a Geographic search using the event's Area of Interest & dates.\n\t- Click **List** to launch a list search including all of the event's product scenes.\n\t- Click **SARVIEWS** to be directed to the SARVIEWS page for your chosen event.\n\t- The eye icon labeled **Open in Image Viewer** opens a larger browse viewer window.\n\t\t- *Note*: When viewing InSAR images in the image viewer, the wrapped browse image is displayed. The unwrapped browse image is available in the downloaded product.\n\t\t- In the browse viewer, **zoom** using the **+** or **-** buttons. You may also zoom and pan using the mouse.\n\t\t- Click or scroll through the thumbnails at the bottom to see other browse images for the selected event.\n\t\t- The scene metadata is listed on the right side of the browse viewer window.\n\t\t- Under **File**, you may click the button labeled **RTC GAMMA** or **INSAR GAMMA** for more options\n\t\t\t- Click **Download File** to download the selected product.\n\t\t\t- Click **Add file to queue** to add it to your Download queue.\n\t\t\t- Click **Reference Scenes** to copy the reference scene names to the clipboard. These may be saved in a file or used in **List** Search.\n\t\t\t- Click **Pin Browse to Map** to pin the browse image to the map. Once pinned, you may click this button again to unpin.\n\t- Click the **Download this image** icon to download the browse image.\n\t- Click the **Pin** icon to pin the selected browse image to the map. Once pinned, you may click this button again to unpin.\n- The Files column (right).\n\t- The total number of files for the selected event is listed in this column.\n\t- You may sort the files using the **Sort By** and **Order** buttons at the top of the column.\n\t\t- Under **Sort By**, you may choose **Date**, **Path**, or **Frame**. \n\t\t- Click the **Order Arrow** to switch between ascending and descending order.\n\t- Click **Product Criteria** to open the Search Filters.\n\t- Click the **checkboxes** next to each file to select or deselect the file. The selected files will be pinned onto the map. Once your desired files are selected, you may also use the **Download** or **Copy** controls in the top left of the results panel to interact with selected products.\n\t- Click **On Demand** to add the selected file to your On Demand queue for further processing.\n\t- Click the **Shopping Cart** icon to add the selected file to your Download queue.\n\t- Click **Download** to download the selected file.\n\t- *Note*: You must be logged in to download products.\n\n\n",
  "EXCEPTIONS_1": "# Exceptions\n\n**ASFError(Exception):**\n\n- Base ASF Exception, not intended for direct use\n\n**ASFSearchError(ASFError):**\n\n- Base search-related Exception\n\n**ASFSearch4xxError(ASFSearchError):**\n\n- Raise when SearchAPI returns a 4xx error\n\n**ASFSearch5xxError(ASFSearchError):**\n\n- Raise when SearchAPI returns a 5xx error\n\n**ASFServerError(ASFSearchError):**\n\n- Raise when SearchAPI returns an unknown error\n\n**ASFBaselineError(ASFSearchError):**\n\n- Raise when baseline related errors occur\n\n**ASFDownloadError(ASFError):**\n\n- Base download-related Exception\n\n**ASFAuthenticationError(ASFError):**\n\n- Base download-related Exception",
  "HTSEA_DATA_1": "# How to Use ASF's Data\nThis provides an overview of some potential uses for the products available through ASF. The [Overview](/datasets/using_ASF_data/#overview) section provides usage examples for each dataset, including dervived datasets, as well as the spatial coverage and mission dates for each. [Dataset Details](/datasets/using_ASF_data/#dataset-details) provides further detail on some of the products available through each dataset. There is also a [Further Reading](/datasets/using_ASF_data/#further-reading) section.\n\n## Overview\n\nDataset   | Dates  | Usage Examples | Spatial Coverage\n--------- | ------ | -------------- | ----------------\n[Sentinel-1](/datasets/using_ASF_data/#sentinel-1) | 2014 - Present | Volcanoes, earthquakes, glaciers, land subsidence, sea ice, flooding, oceans, and more | Global\n[Sentinel-1 Bursts](/datasets/using_ASF_data/#sentinel-1-bursts) | 2014 - Present | Volcanoes, earthquakes, glaciers, land subsidence, sea ice, flooding, oceans, and more | Global\n[OPERA Sentinel-1](/datasets/using_ASF_data/#opera-sentinel-1) | 2014 - Present (varies by product) | Volcanoes, earthquakes, glaciers, land subsidence, sea ice, flooding, oceans, and more | Near-Global or North America (varies by product)\n[ALOS PALSAR](/datasets/using_ASF_data/#alos-palsar) | 2006 - 2011 | Glaciers, landslides, volcanoes, earthquakes, oil seeps, wetlands, sea ice, and more | The Americas, Antarctica, select wordwide sites\n[ALOS AVNIR-2](/datasets/using_ASF_data/#alos-avnir-2) *(Optical dataset)* | 2006 - 2011 | Spatial coverage maps for land and coastal zones; monitoring regional environments | Global\n[SIR-C](/datasets/using_ASF_data/#sir-c) | 1994 | Carbon cycle, ecosystems, biogeochemistry, climate variability and change, land use, geology, hydrology, oceanography, snow and ice, vegetation, calibration, and technological experiments | Targeted worldwide sites\n[ARIA S1 GUNW](/datasets/using_ASF_data/#aria-s1-gunw) | 2014 - Present | Deformation caused by earthquakes, volcanic eruptions, glacier movements, landslides, subsidence, and more | Select worldwide sites\n[SMAP](/datasets/using_ASF_data/#smap-soil-moisture-active-passive) | 2015 - Present | Soil moisture and freeze/thaw state (detailed data from 3 months in 2015); Benchmark data for flood, landslide, and drought monitoring; agricultural planning; and climate forecasting | Global\n[UAVSAR](/datasets/using_ASF_data/#uavsar) | 2008 - Present | Oil spills, earthquakes, volcanoes, oceans, land cover, earthquakes, wildfire scars, glaciers, subsidence, and more | Targeted worldwide sites\n[RADARSAT-1](/datasets/using_ASF_data/#radarsat-1) | 1996 - 2008 | Arctic sea ice, volcanoes, ocean winds, ecology, soil moisture, wetlands, flooding, and more | Global\n[ERS-1 & ERS-2](/datasets/using_ASF_data/#ers) | 1991 - 2011 | Polar regions and processes (sea ice, Arctic, Antarctic) | Primarily polar, within station masks of the ASF and McMurdo ground stations\n[JERS-1](/datasets/using_ASF_data/#jers) | 1992 - 1998 | Important forests of the world: Southeast Asia, Africa, Central America, South America (Amazon Basin), and boreal North America | Global\n[AIRSAR](/datasets/using_ASF_data/#airsar) | 1990 - 2004 | Oceans, coasts, forest ecology, geology, hydrology, earthquakes, archeaology, and more | Selected sites worldwide\n[Seasat](/datasets/using_ASF_data/#seasat) | 1978 | Portions of northern oceans and land | Regions of Northern Hemisphere, including oceans and North America\n[Global Seasonal Sentinel-1 Interferometric Coherence and Backscatter Dataset](/datasets/using_ASF_data/#global-seasonal-sentinel-1-interferometric-coherence-backscatter-dataset) | 2019 - 2020 | Deformation caused by earthquakes, volcanic eruptions, glacier movements, landslides, and subsidence, and more | All land masses and ice sheets from 82°N to 78°S\n[GISMO](/datasets/using_ASF_data/#gismo) | 2006 - 2008 | Glaciers, ice sheets | Greenland Ice Sheet\n[Glacier Speed](/datasets/using_ASF_data/#glacier-speed) | 2007 - 2011 | Glaciers, glacial flow speeds, ocean-ice sheet interactions | Glaciers in Alaska\n[International Polar Year](/datasets/using_ASF_data/#international-polar-year) | 2007 - 2008 | Arctic and Antarctic relationships with geophysical elements, oceans and sea ice, Earth’s atmosphere, space, human relations, climate change | Arctic & Antarctic\n[RADARSAT-1 Antarctic Mapping Mission (RAMP)](/datasets/using_ASF_data/#ramp) | 1997 and 2000 | Historic, high-resolution map of Antarctica: ice-sheet morphology, rock outcrops, research infrastructure, coastline, and more | Antarctica\n[Sea Ice MEaSUREs](/datasets/using_ASF_data/#sea-ice-measures) | 1995 - 2012 | Arctic Ocean sea ice motion with three-day radar snapshots as the ice goes through dramatic changes over 11 years | Arctic Ocean\n[Wetlands MEaSUREs](/datasets/using_ASF_data/#wetlands-measures) | 1993 - 2009 | Wetlands ecology, including their role in climate, biogeochemistry, hydrology, and biodiversity | Amazon, Alaska, the Americas, global (coarse resolution)\n\n\n## Dataset Details\n\n### Sentinel-1\nSentinel-1 offers global coverage with C-Band SAR. Sentinel-1A was launched in 2014, and Sentinel-1B was launched in 2016. Each satellite has a 12 day repeat cycle, and some areas have coverage every 6 days. New acquisition data is available to download within 3 days, though it is most often available within 24 hours. The data is free and easy to download in several formats.\n\n*Note*: As of December 23, 2021, the Sentinel-1B mission has ended due to an anomaly. This affects the coverage cycle in some areas. More information can be found [here](https://sentinels.copernicus.eu/web/sentinel/-/end-of-mission-of-the-copernicus-sentinel-1b-satellite/1.5).\n\n#### RAW\nRAW products require calibration & processing steps before the data is analysis-ready. These products are best suited for use by SAR specialists.\n\n#### GRD\nGround Range Detected (GRD) products are best for amplitude applications, such as generating RTC images. These are Level 1 products. These products are georeferenced, and multi-looked into a single image. Only amplitude information is included in the GRD.\n\n- No effort required to view data in a GIS software\n- Easy to project to desired coordinate system\n- Pixels are in ground-detected geometry\n- One consolidated image for each polarization\n- Square pixels\n- Smaller file size\n\n#### SLC\nSingle Look Complex (SLC) products are necessary for interferometry. These are Level 1 products. These products are comprised of 3 GeoTIFFs, one for each of the sub-swaths, and each radar burst is included in the data. The SLC includes phase data.\n\n- Remains in slant-range geometry\n- Phase data is retained\n\t- Suitable for detecting changes in surface elevation\n\t- Required for generating interferograms\n- Several images for each SLC\n- Retains each subswath (including overlap) and series of bursts, with a black line grid\n\n#### OCN\nOCN products are higher level products, generated from the Level 1 products. These products are focused on ocean applications, including waves & wind direction. \n\n### Sentinel-1 Bursts\nA Sentinel-1 SLC contains multiple measurement TIFFs that contain the radar response data. Each measurement TIFF can be further broken down into a single radar pulse response message which is referred to as a burst.\n\nThere are multiple parameters that allow searching for bursts across sub-swaths and burst cycles. Depictions of a single burst, and the three available burst-related IDs are below.\n\nSingle burst:  \n![Screenshot](/images/single_burst_diagram.png){: style=\"height:150px;width:150px\"}\n\nAbsolute Burst ID:  \n![Screenshot](/images/absolute_burst_id_diagram.png){: style=\"height:150px;width:150px\"}\n\nRelative Burst ID:  \n![Screenshot](/images/relative_burst_id_diagram.png){: style=\"height:150px;width:150px\"}\n\nFull Burst ID:  \n![Screenshot](/images/full_burst_id_diagram.png){: style=\"height:150px;width:150px\"}\n\nEach burst file also has a corresponding XML Metadata file available. The Burst XML Metadata is a virtually generated file, and therefore does not have its own unique filename. The XML Metadata can only be found via the burst scene name, and is not searchable in a list search.\n\n### OPERA Sentinel-1\nObservational Products for End-Users from Remote Sensing Analysis [(OPERA)](https://www.jpl.nasa.gov/go/opera/about-opera?_ga=2.199717550.185027135.1698074247-1558404154.1684781882) is a project at the Jet Propulsion Laboratory [(JPL)](https://www.jpl.nasa.gov/go/opera?_ga=2.266246031.185027135.1698074247-1558404154.1684781882), created to address high-priority requests from the NASA [Satellite Needs Working Group](https://impact.earthdata.nasa.gov/project/snwg.html?_ga=2.199717550.185027135.1698074247-1558404154.1684781882) and its partners for products generated from SAR and optical sensors.\n\nThe following OPERA products can be found through Vertex, asf_search, or the SearchAPI:\n \n- Near-global land surface Radiometric Terrain Corrected (RTC) backscatter product\n- Near-global land surface Radiometric Terrain Corrected (RTC) backscatter static layers product\n- North America Coregistered Single-Look Complex (CSLC) product\n- North America Coregistered Single-Look Complex (CSLC) static layers product\n\n“Near-global” corresponds to all landmasses excluding Antarctica. “North America” corresponds to the United States and U.S. Territories, Canada within 200 km of the U.S. border, and all mainland countries from the southern U.S. border up to and including Panama.\n\nThe near-global RTC products are available from 2023 to present. The North America CSLC products will be available from 2014 to present.\n\n####RTC\nThe Radiometric Terrain Corrected (RTC) Backscatter product consists of Sentinel-1 radar backscatter data normalized with respect to the topography. It is a Level-2 product that is projected onto a pre-defined UTM/Polar stereographic map projection system. The Copernicus Global 30 m (GLO-30) Digital Elevation Model (DEM) is the reference DEM used to correct for the impacts of topography and to geocode the product. The product is provided in a GeoTIFF file format. The RTC metadata is in HDF5 format.\n\n####RTC Static\nThe RTC-STATIC product is a Level 2 product that contains static radar geometry layers associated with the RTC product.\n\n####CSLC\nThe Coregistered Single-Look Complex (CSLC) product consists of SLC images that are precisely aligned or “coregistered” to a pre-defined UTM/Polar stereographic map projection system. The CSLC images contain both the amplitude and phase information of the complex radar return. The Level-2 CSLC product is derived from Sentinel-1 data and is provided in HDF5 format.\n\n####CSLC Static \nThe CSLC-ST product serves as an ancillary product to the CSLC products and is distributed separately from the CSLC products. It is only produced once (or a limited amount of times) for CSLC products characterized by the same burst identification string i.e., for all the Sentinel-1-A/B bursts covering the same geographical area on the ground.\n\n### ALOS PALSAR\nALOS PALSAR offers historical data, and has some analysis-ready RTC (Radiometric Terrain Corrected) products, processed by ASF. \n\n#### RTC\nNote that a resampled DEM (SRTM or NED) was used for RTC processing. DEM information can be found [here](https://asf.alaska.edu/information/palsar-rtc-dem-information/). These RTCs can be used to replace optical imagery in areas with frequent cloud cover. They may also be used to improve land cover classification. More advanced processing techniques include data fusion, either on a pixel level or on a feature level, using an object-oriented approach.\n\n- Projected to UTM coordinates\n- Hi-Res Terrain Corrected products are 12.5 meter resolution\n- Low-Res Terrain Corrected products are 30 meter resolution\n\nThe ALOS PALSAR Product Guide can be found [here](https://asf.alaska.edu/wp-content/uploads/2019/03/rtc_product_guide_v1.2.pdf).\n\n#### Level 2.2\nThese products are projected in a custom Japan Aerospace Exploration Agency (JAXA) datum. These products require reprojection to the appropriate UTM zone before they can be analyzed in a GIS software.\n\n#### Level 1.5\nThese products are in CEOS data format, and do not contain a spatial reference. These must be geocoded before any processing or analysis. Once geocoded, these may be exported as GeoTIFF files. This [data recipe](https://asf.alaska.edu/how-to/data-recipes/how-to-view-and-geocode-ceos-data-in-asf-mapready/) uses ASF’s MapReady software to view and geocode CEOS format files.\n\n### ALOS AVNIR-2\nALOS AVNIR-2 is an optical dataset that offers historical data. These products are ortho rectified images (ORI). Orthorectification is the process of removing image distortions caused by the sensor and terrain to create a planimetric image at every location with consistent scale across all parts of the image. This allows the overlay of various geospatial information with the ORI on any map. The products contain 4 bands, and each image has 30% cloud cover or less.\n\n### SIR-C\nSIR-C was flown on two missions, six months apart. The first mission dates were April 9-20, 1994 and the second mission dates were September 30-October 11, 1994. The second flight followed nearly the same orbit as the first flight. Therefore, there are repeat-pass products available, enabling interferometric SAR processing over these areas.\n\n### ARIA S1 GUNW\nThese products are already processed interferograms. You may download either the full netCDF product, or select GeoTIFF layers. These are analysis-ready InSAR products. These products do have a limited spatial coverage.\n\n### SMAP (Soil Moisture Active Passive)\nSMAP was launched with both an active and a passive sensor to collect high-resolution soil moisture data globally. Unfortunately, the active SAR sensor malfunctioned a few months into the mission. The passive sensor is still ongoing. With only the passive sensor functional, the soil moisture data is in a coarse resolution. The coarse resolution products can still be used for regional analysis or larger-scale projects.\n\n- 2015 - Present\n\t- Active sensor data available for the first 3 months\n- L-band\n- Measures soil moisture and freeze-thaw state in top 5 cm of soil globally every three days (multi-kilometer resolution)\n\t- High resolution capabilities lost with loss of active sensor\n\t- Recent efforts to integrate Sentinel-1 data have generated higher-resolution products\n- Variety of soil moisture products available [here](https://smap.jpl.nasa.gov)\n\n### UAVSAR\nUAVSAR offers airborne acquisitions of targeted locations. Because the acquisitions are targeted, there are generally not repeat passes over one area. However, if UAVSAR covers your area of interest, this dataset includes a variety of available products.\n\n- 2008 - present\n- Quad-pol L-band\n- Airborne, targeted locations, irregular timing\n- Flights can be requested for your area of interest\n- Pre-processed backscatter and interferometric products\n\t- PolSAR and Repeat-Pass Interferometry\n\n#### KMZ\nThese products are georeferenced products. These can be used in Google Earth, or other applications that support kmz format files. These products have a 6 meter pixel spacing.\n\n- **Beam Mode POL**: These contain a polarimetry single-pass product, using a quad-pol backscatter decomposition.\n\t- Red: HH; Green: HV; Blue: VV\n- **Beam Mode RPI**: These products are generated from two passes. In addition to the polarimetry product, these also include amplitude, correlation, interferometry, and digital elevation map products.\n\t- The amplitude product contains backscatter for each polarization\n\t- The correlation product is phase coherence between passes\n\t- The interferometry product shows landscape changes\n\t- The digital elevation map product is for reference\n\n### RADARSAT-1\nThese products are in CEOS data format, and do not contain a spatial reference. These must be geocoded before any processing or analysis, and once geocoded, may be exported as GeoTIFF files. RADARSAT-1 is restricted data, and requires a [research agreement](https://asf.alaska.edu/restricted-data-access-request/) to download. This [data recipe](https://asf.alaska.edu/how-to/data-recipes/how-to-view-and-geocode-ceos-data-in-asf-mapready/) uses ASF’s MapReady software to view and geocode CEOS format files.\n\n- Level 0 products are unprocessed / raw data\n- Level 1 products are amplitude processed images\n\n### ERS \nThese products are in CEOS data format, and do not contain a spatial reference. These must be geocoded before any processing or analysis, and once geocoded, may be exported as GeoTIFF files. This [data recipe](https://asf.alaska.edu/how-to/data-recipes/how-to-view-and-geocode-ceos-data-in-asf-mapready/) uses ASF’s MapReady software to view and geocode CEOS format files.\n\n- ASF holds a subset of the ERS data, focused on Alaska, Western Canada, Chukotka and Antarctica\n- Level 0 products are unprocessed / raw data\n- Level 1 products are amplitude processed images\n\n### JERS\nThese products are in CEOS data format, and do not contain a spatial reference. These must be geocoded before any processing or analysis, and once geocoded, may be exported as GeoTIFF files. JERS-1 is restricted data, and requires a [research agreement](https://asf.alaska.edu/restricted-data-access-request/) to download. This [data recipe](https://asf.alaska.edu/how-to/data-recipes/how-to-view-and-geocode-ceos-data-in-asf-mapready/) uses ASF’s MapReady software to view and geocode CEOS format files.\n\n- Level 0 products are unprocessed / raw data\n- Level 1 products are amplitude processed images\n\n### AIRSAR\nAIRSAR offers airborne acquisitions of targeted locations. These acquisitions cover primarily the United States, and some tropical locations. The campaign name listed for each product is its acquisition location. Because the acquisitions are targeted, there are generally not repeat passes over one area. However, if AIRSAR covers your area of interest, there are a variety of sensors and frequencies available. There are JPGs available, though they are not georeferenced.\n\n#### Beam Mode: POLSAR or 3FP\nIn POLSAR mode, fully polarimetric data are acquired at all three frequencies in P-, L-, C-band for 40 Mhz or 20 Mhz. The L-band also provides 80 MHz bandwidth data. POLSAR data are sensitive to the geometry (including vegetation) and dielectrical properties (water content) of the terrain.\n\n#### Beam Mode: TOPSAR or XTI\nIn TOPSAR mode, AIRSAR collects interferometric data using C- and L-band to produce digital elevation models (DEMs). The radars which are not being used for interferometry collect quad-pol data co-registered with the C-band DEM.  Interferometric data can be collected in \"ping-pong\" mode, where each antenna is used alternately for transmit and the effective baseline is doubled, and in \"common-transmitter\" mode where only one antenna is used for transmit.\n\n#### Beam Mode: ATI\nIn the along-track interferometry (ATI) mode, AIRSAR collects data C- and L-band. Data collected can be used to measure ocean current velocities. \n\n### Seasat\nSeasat was the first spaceborne SAR mission, launched in 1978. This data has been processed by ASF into digital imagery. These products may have substantial geolocation errors.\n\n#### HDF5\nThe backscatter values are contained in the HH layer. In order to provide basic geolocation information, two additional layers, latitude and longitude, are added. They contain geographic coordinates for every pixel in the image. The time variable completes the compliance to the Climate and Forecast (CF) metadata conventions.\n\n#### GeoTIFF\nThese products are geocoded to the UTM map projection, using the zone that best represents the data's geolocation. The original 12.5 meter pixel size and the floating-point values of the ground range HDF5 products are kept in the GeoTIFF format. This product type contains only a single layer, and is therefore considerably smaller than the HDF5 product.\n\n### Global Seasonal Sentinel-1 Interferometric Coherence & Backscatter Dataset\nThis dataset is the first-of-its-kind spatial representation of multi-seasonal, global SAR repeat-pass interferometric coherence and backscatter signatures. Global coverage comprises all land masses and ice sheets from 82 degrees northern to 78 degrees southern latitude. The dataset is derived from high-resolution multi-temporal repeat-pass interferometric processing of about 205,000 Sentinel-1 Single-Look-Complex (SLC) data acquired in Interferometric Wide-Swath (IW) mode from Dec 1, 2019 to Nov 30, 2020.\n\nThe dataset covers several seasonal metrics, listed below. The seasons consist of December, January, February (DJF); March, April, May (MAM); June, July, August (JJA); and September, October, November (SON).\n\n- Median 6-, 12-, 18-, 24-, 36-, and 48-day repeat coherence estimates for C-band VV and HH polarized data\n- Mean backscatter (γº) for VV, VH, HH, and HV polarizations\n- Seasonal coherence decay model parameters rho, tau, and rmse\n- Local incidence and layover/shadow regions for all relative Sentinel-1A and Sentinel-1B orbits. Note that in the dataset filenames seasons were referred to as northern hemisphere winter (DJF), spring (MAM), summer (JJA), and fall (SON).\n\n#### Data Products\n- Coherence Tiles separated by latitude\n- Virtual Raster tables\n- Global mosaics separated into seasons\n\n### GISMO\nThe Global Ice-Sheet Mapping Observatory (GISMO) project had a specific focus in measuring the surface topography of ice sheets, ice-sheet thickness, and in uncovering physical properties of the glacier bed using SAR.\n\nThe GIMSO project had documented flight lines over the Greenland Ice Sheet in 2006, 2007, and 2008. It utilized VHF and P-band interferometric radars and tested different methods of clutter rejection in order to find the method most suitable for the project’s focus.\n\nGISMO achieved mapping the physical properties of a glacier bed through up to 5 km of ice. It also created an effective clutter rejection technique for measuring the ice sheet’s surface and base. GISMO has applications in predicting the effects of climate change on ice sheets and in exploring planets with icy areas.\n\n#### Data Products\n- 150 MHz Data Products: May 23, 2006\n- 450 MHz Data Products: Sept 10, 2007\n- 150 MHz Data Products: Sept 12, 2007\n- Low Aircraft Elevation Data Products: 2008\n- High Aircraft Elevation Data Products: 2008\n\nFor these products, each flight line was segmented into approximately 25 km long sections with 20% overlap on each end.\n\n### Glacier Speed\nGlacier Speed is the first near-comprehensive dataset of wintertime glacier-flow speeds throughout Alaska, and reveals complex patterns of glacier flow throughout the state. The findings significantly advance understanding of the mechanisms responsible for the rapid glacier mass loss occurring in Alaska. \n\nThe patterns include glacier surging and spatial variations in flow related to climate. Notably, the data show that out of tens of thousands of glaciers in Alaska, only 12 are responsible for the majority of downstream ice flux. These glaciers are flowing exceptionally fast because they receive very high rates of snowfall and are not necessarily flowing fast because of tidewater retreat. (The flow speed is not the same as the melt rate; melting is strong enough at low elevations that it is outpacing the high snowfall rates.)\n\nThe data have also revealed that iceberg calving in Alaska is an important component of the statewide glacier mass budget: The volume of calved ice is 17.1 km3 – or roughly equivalent to a third of the annual net glacier mass change in Alaska.\n\n#### Data Products\n- KMZ format statewide glacier-flow-speed map\n- ZIP file that includes readme file and a speed.tif, ids.tif, and .par file for each of the nine regions\n\nThe nine regions are: Central Alaska Range, Chugach Mountains, Coastal Range, Delta Range, Fairweather Range - Glacier Bay, Hayes Range, Kenai Mountains, Tordrillo Mountains, and Wrangell Mountains - St. Elias Mountains\n\nThe flow-speed data are gridded on 90-meter-resolution UTM grids as GeoTIFFs. The grids are divided into different regions and include a speed file that contains the mosaicked flow speed in meters/day (32-bit float) and a ids file that contains integer IDs that correspond to the image pair used for determining flow speed at each pixel (16-bit integer).\n\nThe dates of the image pairs used can be found by looking up image IDs in the corresponding .par file. In some cases, the .par file will contain IDs that are not in the ids grid. In these cases, these image pairs were simply not needed in the final mosaic. The .par file also includes georeference information in a text format.\n\n### International Polar Year\nASF hosts an archive of the International Polar Year (IPY) project titled the Global Inter-agency IPY Polar Snapshot Year (GIIPSY). GIIPSY’s objective was to obtain high-definition satellite snapshots of the polar regions during 2007-2008. The primary purpose is to use these snapshots as benchmarks for gauging past and future environmental changes in the polar ice, ocean, and land.\n\n#### Data Products\n- Greenland L0 Kongsberg\n- Greenland Level 0 (September 2000-January 2001)\n- Greenland Level 1 (September 2000-January 2001)\n- Antarctica Level 1 (September 2000-January 2001)\n- Toolik Station Level 1 (October 2004-December 2006)\n- Kamchatka Level 1 (December 1999-January 2000)\n- Sea Ice Snapshots (Min & Max Snapshots, September-March of 2003-2004, 2004-2005, 2005-2006, 2006-2007)  \n\n### RAMP\nThe RADARSAT-1 Antarctic Mapping Project (RAMP) was composed of two main missions, the first Antarctic Mapping Mission (AMM-1) and the Modified Antarctic Mapping Mission (MAMM). Both missions utilized RADARSAT-1.\n\nAMM-1 started on September 9, 1997 and was completed on October 20, 1997. Its goals were to acquire a complete map of Antarctica and better understand the relationships between the southernmost continent’s environmental elements. Using the right- and left-looking abilities of RADARSAT-1, a mosaic map of Antarctica at 25 meter resolution was created. The map displayed Antarctica’s geological features through variations in radar brightness and texture, including ice streams. Ice velocity vectors were compiled using AMM-1 data to measure ice sheet movement over ice streams.\n\nMAMM began three years after AMM-1 ended, starting on September 3, 2000 and ending on November 17, 2000. It planned to remap Antarctica and measure ice velocity data using interferometric analysis and data from AMM-1. In the three years’ difference between the two main Antarctic Mapping Missions, ice sheet advance and retreat could be observed and better evaluated as episodic change or regional climate change.\n\n#### Data Products\n- 25 meter Final Tiles\n- 25 meter Tile Overviews\n- 16 bit 25 meter Tile Overviews of the backscatter coefficient in dB\n- 200 meter Final Coherence (ascending and descending)\n- 200 meter Coherence Overviews (ascending and descending)\n- A variety of mosaic products\n- AMM-1 & MAMM Coastline\n- AMM-1 & MAMM Control points\n- DEMs\n- East Antarctic\n- Velocity Product\n- Balance Velocity Map\n\n### Sea Ice MEaSUREs\nThe data and imagery available from ASF cover a period from 1995 to 2011. They include more than 11 years of near-uninterrupted, three-day radar snapshots of Arctic and Southern Ocean’s sea ice as it goes through dramatic change.\n\nUses include:\n\n- New approaches for modeling the mechanical behavior of sea ice and the validation of these models\n- Characterization of sub-daily ice motion \n- Description of the seasonal and regional variability of sea-ice deformation\n- Validation of ICESat freeboard algorithms\n- Estimates of sea-ice exchange between the Arctic and Southern Oceans and peripheral seas\n\n#### Data Products\n- A dataset of small-scale kinematics and deformation processed by tracking sea ice on a high-resolution grid. \n- The original synthetic aperture radar (SAR) images.\n\n### Wetlands MEaSUREs\nThese products from the NASA Inundated Wetlands MEaSUREs project facilitate investigations on the role of wetlands in climate, biogeochemistry, hydrology, and biodiversity.\n\nThe inundated wetlands Earth System Data Records consists of two primary components:\n\n1. Fine-resolution maps of wetland extent, vegetation type, and seasonal inundation dynamics, derived from SAR for regional and continental-scale areas covering crucial wetlands systems. These are created using data from a variety of spaceborne SARs. The wetlands datasets were generated using algorithms appropriate to the nature of the wetlands systems under study, including time series and statistically-based tree classifiers.\n2. Global, coarse-resolution time series mappings of inundated area fraction at 25 km resolution derived from multiple satellite remote sensing observations including passive and active microwave sensors and optical data sets optimized for inundation detection. The algorithm employed in the generation of this dataset employs a clustering model and a mixture model in the classification of fractional inundated areas. These datasets are provided on a bi-monthly basis for 1992-1999 and daily for 2000 onward. Annual summary products, including maximum inundated extent and annual inundation duration, are provided. A daily near real time (NRT) dataset with 2-3 day latency is also provided.\n\n#### Data Products\n- Surface WAter Microwave Product Series (SWAMPS)\n- North America JERS-1 Mosaics\n- Alaska Wetlands Map derived from ALOS PALSAR fine beam data\n- Alaska Wetlands Map derived from JERS-1 SAR\n- Amazon Low and High Flood Backscatter Mosaics from JERS-1 SAR\n- Time-series Amazon Wetlands Extent Maps derived from PALSAR ScanSAR data\n\n## Further Reading\n\n- [What is SAR?](https://asf.alaska.edu/information/sar-information/what-is-sar/#sar_faq)\n- [Video Introduction to SAR](https://www.youtube.com/watch?v=Zfn7P395O40)\n- [Video Overview of ASF's SAR Datasets](https://www.youtube.com/watch?v=0ZzLg38cC8I)\n- [Data Recipe Library](https://asf.alaska.edu/how-to/data-basics/data-recipe-tutorials-2/)\n- [Data Recipes for ASF SAR Datasets in GIS Applications](https://asf.alaska.edu/how-to/data-basics/sar-data-and-gis/)\n- [Dataset Formats and Files](https://asf.alaska.edu/how-to/data-basics/asf-datasets-formats-and-files/)\n- [Product Types and Processing Levels](https://asf.alaska.edu/how-to/data-basics/types-of-synthetic-aperture-radar-sar-products/)\n- [Derived Datasets Overview](https://docs.asf.alaska.edu/vertex/derived_datasets/)\n",
  "INDEX_1": "\n# Welcome to ASF SAR Data Search\n\n## About ASF Data Search\n\n[ASF Data Search](https://search.asf.alaska.edu/) is an easy to use search tool for finding SAR data and freely processing higher level SAR products such as InSAR and AutoRIFT products with ASF's [HyP3 service](https://hyp3-docs.asf.alaska.edu). See our user guide on [getting started](vertex/manual.md).\n\nFor an overview of all of ASF services visit [asf.alaska.edu](https://asf.alaska.edu).\n\n<div class=\"documentation-block\">\n<h2 class=\"text-center documentation-header\" style=\"margin-top: 35px; margin-bottom: 25px;\">Search Tool Documentation</h2>\n\n<div class=\"row\">\n  <div class=\"row-container\">\n    <div class=\"card\">\n      <div class=\"card-body\">\n        <h3 class=\"card-title text-center\">Vertex</h3>\n        <p class=\"card-description\">A graphical search interface for finding SAR data.</p>\n        <ul class=\"doc-links\">\n          <li><a href=\"vertex/manual/\">Geographic & List Search Tools</a></li>\n          <li><a href=\"vertex/baseline/\">Baseline Search Tool</a></li>\n          <li><a href=\"vertex/sbas/\">SBAS Search Tool</a></li>\n          <li><a href=\"https://www.youtube.com/playlist?list=PLXluIEvp5ZzIWd0yNy-ANfdwWjCD1hInA\">Tutorial</a></li>\n          <li><a href=\"vertex/changelog/\">What's New</a></li>\n        </ul>\n      </div>\n    </div>\n  </div>\n  <div class=\"row-container\">\n    <div class=\"card\">\n      <div class=\"card-body\">\n        <h3 class=\"card-title text-center\">HyP3</h3>\n        <p class=\"card-description\">Process SAR data to create refined products.</p>\n        <ul class=\"doc-links\">\n          <li><a href=\"https://hyp3-docs.asf.alaska.edu\">Custom Processing</a></li>\n          <li><a href=\"https://hyp3-docs.asf.alaska.edu/products/\">Products</a></li>\n          <li><a href=\"https://hyp3-docs.asf.alaska.edu/using/sdk/\">SDK</a></li>\n          <li><a href=\"https://hyp3-docs.asf.alaska.edu/using/api/\">API</a></li>\n        </ul>\n      </div>\n    </div>\n  </div>\n</div>\n\n<div class=\"row\">\n  <div class=\"row-container\">\n    <div class=\"card\">\n      <div class=\"card-body\">\n        <h3 class=\"card-title text-center\">asf_search</h3>\n        <p class=\"card-description\">A Python module for performing searches of the ASF catalog.</p>\n        <ul class=\"doc-links\">\n          <li><a href=\"asf_search/basics/\">Basics</a></li>\n          <li><a href=\"asf_search/searching/\">Searching</a></li>\n          <li><a href=\"asf_search/downloading/\">Downloading</a></li>\n          <li><a href=\"https://github.com/asfadmin/Discovery-asf_search/blob/master/CHANGELOG.md/\">What's New</a></li>\n        </ul>\n      </div>\n    </div>\n  </div>\n  <div class=\"row-container\">\n    <div class=\"card\">\n      <div class=\"card-body\">\n        <h3 class=\"card-title text-center\">ASF API</h3>\n        <p class=\"card-description\">A command-line interface for finding SAR data.</p>\n        <ul class='doc-links'>\n          <li><a href=\"api/basics/\">Basics</a></li>\n          <li><a href=\"api/keywords/\">Keywords</a></li>\n          <li><a href=\"api/tools/\">Tools</a> </li>\n          <li><a href=\"api/changelog/\">What's New</a></li>\n        </ul>\n      </div>\n    </div>\n  </div>\n</div>\n</div>",
  "KEYWORDS_1": "# Search API Keywords\n\nConsider using our new Python module, asf_search. asf_search can be used to perform searches of the ASF catalog, and it offers baseline functionality and download support. Additionally, numerous constants are provided to ease the search process. Currently, we provide constants for platform, instrument, beam mode, flight direction, polarization, and processing level. More information can be found [here](/asf_search/basics).\n\nKeywords are used to find the desired data. Use as many or as few keywords as needed. Available keywords and descriptions are listed below for each Search API endpoint. Keywords are case sensitive.\n\n*Note:* Any errors will be returned in JSON format.\n\n## Search Endpoint\n<https://api.daac.asf.alaska.edu/services/search/param>\n\n### Dataset Parameters\n- <span style=\"color: #236192; font-size: 20px;\">dataset</span>\n\t- This is the preferred alternative keyword for 'platform' searches.\n\t- Remote sensing platform that acquired the data. You may specify a single value, or a list of values.\n\t- Example:\n\t\t- dataset=SENTINEL-1\n\t\t- dataset=OPERA-S1\n\t\t- dataset=AIRSAR,UAVSAR\n\t- Values:\n\t\t- [SENTINEL-1](/datasets/using_ASF_data/#sentinel-1), [SLC-BURST](/datasets/using_ASF_data/#sentinel-1-bursts), [OPERA-S1](/datasets/using_ASF_data/#opera-sentinel-1), [ALOS PALSAR](/datasets/using_ASF_data/#alos-palsar), [ALOS AVNIR-2](/datasets/using_ASF_data/#alos-avnir-2), [SIR-C](/datasets/using_ASF_data/#sir-c), [ARIA S1 GUNW](/datasets/using_ASF_data/#aria-s1-gunw), [SMAP](/datasets/using_ASF_data/#smap-soil-moisture-active-passive), [UAVSAR](/datasets/using_ASF_data/#uavsar), [RADARSAT-1](/datasets/using_ASF_data/#radarsat-1), [ERS](/datasets/using_ASF_data/#ers), [JERS-1](/datasets/using_ASF_data/#jers), [AIRSAR](/datasets/using_ASF_data/#airsar), [SEASAT](/datasets/using_ASF_data/#seasat)\n\n- <span style=\"color: #236192; font-size: 20px;\">platform</span>\n\t- See also 'dataset'. Dataset is the preferred keyword when possible.\n\t- This keyword has constants provided through asf_search. More information can be found [here](/asf_search/searching/#keywords).\n\t- See also 'instrument'\n\t- Remote sensing platform that acquired the data. Sentinel-1 and ERS have multiple remote sensing platforms, and you may choose whether to specify a specific platform. You may specify a single value, or a list of values.\n\t- Example:\n\t\t- platform=ALOS\n\t\t- platform=SA,SB\n\t\t- platform=S1\n\t- Values:\n\t\t- ALOS, A3, AIRSAR, AS, ERS, ERS-1, E1, ERS-2, E2, JERS-1, J1, RADARSAT-1, R1, SEASAT, SS, S1, Sentinel, Sentinel-1, Sentinel-1A, SA, Sentinel-1B, Sentinel-1 Interferogram (BETA), SB, SIR-C, SMAP, SP, UAVSAR, UA\n\n- <span style=\"color: #236192; font-size: 20px;\">instrument</span>\n\t- See also 'dataset'. Dataset is the preferred keyword when possible.\n\t- This keyword has constants provided through asf_search. More information can be found [here](/asf_search/searching/#keywords).\n\t- See also 'platform'\n\t- Remote sensing instrument that acquired the data. For some platforms, such as ALOS, there are multiple instruments to choose from.\n\t- Example:\n\t\t- ALOS: instrument=PALSAR\n\t\t- ALOS: instrument=AVNIR-2\n\t- Values:\n\t\t- C-SAR, PALSAR, AVNIR-2\n\n- <span style=\"color: #236192; font-size: 20px; font-size: 20px;\">absoluteOrbit</span>\n\t- This keyword is also available through [asf_search](/asf_search/searching/#searching).\n\t- For ALOS, ERS-1, ERS-2, JERS-1, RADARSAT-1, Sentinel-1A, and Sentinel-1B this value corresponds to the orbit count within the orbit cycle. For UAVSAR it is the [Flight ID](https://uavsar.jpl.nasa.gov/cgi-bin/data.pl?_ga=2.34282209.1335434931.1620087198-1930115146.1605056035). You may specify a single value, range of values, or a list of values.\n\t- Example:\n\t\t- RADARSAT: absoluteOrbit=25436\n\t\t- PALSAR: absoluteOrbit=25436-25445,25450\n\t\t- UAVSAR: absoluteOrbit=12006\n\n- <span style=\"color: #236192; font-size: 20px;\">asfframe</span>\n\t- This keyword is also available through [asf_search](/asf_search/searching/#searching).\n\t- See also 'frame'\n\t- This is primarily an ASF / [JAXA](https://global.jaxa.jp/) frame reference. However, some platforms use other conventions. You may specify a single value, range of values, or a list of values.\n\t- Example:\n\t\t- asfframe=300 or asfframe=2845-2855 or asfframe=2800,2845-2855\n\t- Values:\n\t\t- ERS, JERS, RADARSAT: ASF frames 0 to 900\n\t\t- ALOS PALSAR: JAXA frames 0 to 7200\n\t\t- SEASAT: ESA-like frames 0208 to 3458  (must use a leading zero for frames 208-999)\n\t\t- Sentinel-1: In-house values 0 to 1184\n\n- <span style=\"color: #236192; font-size: 20px;\">maxBaselinePerp</span>\n\t- For interferometric SAR (InSAR) analysis, Perpendicular Baseline is the spatial distance between the first and second observations measured perpendicular to the satellite look direction and provides an indication of the sensitivity to topographic height.\n\t- Works for ERS-1, ERS-2, JERS, RADARSAT-1, ALOS PALSAR. (Not Sentinel-1)\n\t- Example:\n\t\t- maxBaselinePerp=1500 or maxBaselinePerp=50.5\n\n- <span style=\"color: #236192; font-size: 20px;\">minBaselinePerp</span>\n\t- For interferometric SAR (InSAR) analysis, Perpendicular Baseline is the spatial distance between the first and second observations measured perpendicular to the satellite look direction and provides an indication of the sensitivity to topographic height.\n\t- Works for ERS-1, ERS-2, JERS, RADARSAT-1, ALOS PALSAR. (Not Sentinel-1)\n\t- Example:\n\t\t- minBaselinePerp=100 or minBaselinePerp=50.5\n\n- <span style=\"color: #236192; font-size: 20px;\">beamMode</span>\n\t- This keyword has constants provided through asf_search. More information can be found [here](/asf_search/searching/#keywords).\n\t- The beam mode used to acquire the data. See also beamSwath. You may specify a single value, or a list of values.\n\t- Example:\n\t\t- beamMode=FBS or beamMode=EW,IW or beamMode=ScanSAR+Wide\n\t- Values:\n\t\t- AIRSAR: 3FP, ATI, XTI\n\t\t- ALOS: FBD, FBS, PLR, WB1, WB2, DSN\n\t\t- ERS-1: Standard, STD\n\t\t- ERS-2: Standard, STD\n\t\t- JERS-1: Standard, STD\n\t\t- RADARSAT-1: Standard, STD, Fine, High, Low, Wide, Narrow, ScanSAR+Wide, ScanSAR+Narrow\n\t\t- SEASAT: Standard, STD\n\t\t- SMAP: Standard, STD\n\t\t- Sentinel-1A: EW, IW, S1, S2, S3, S4, S5, S6, WV\n\t\t- Sentinel-1B: EW, IW, S1, S2, S3, S4, S5, S6, WV\n\t\t- UAVSAR: POL, RPI\n\n- <span style=\"color: #236192; font-size: 20px;\">beamSwath</span>\n\t- This keyword is also available through [asf_search](/asf_search/searching/#searching).\n\t- BeamSwath encompasses a look angle and beam mode. You may specify a single value, or a list of values.\n\t- Example:\n\t\t- beamSwath=0\n\t\t- beamSwath=FN1, FN2, FN3, FN4, FN5\n\t- Values:\n\t\t- AIRSAR: 3FP, ATI, XTI\n\t\t- ALOS: 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 15, 16, 17, 18, 19, 20\n\t\t- ERS-1: STD\n\t\t- ERS-2: STD\n\t\t- JERS-1: STD\n\t\t- RADARSAT-1: FN1, FN2, FN3, FN4, FN5, SNA, SNB, ST1, ST2, ST3, ST4, ST5, ST6, ST7, SWA, SWB, WD1, WD2, WD3, EH3, EH4, EH6, EL1\n\t\t- SEASAT: STD\n\t\t- Sentinel-1A: EW, IW, S1, S2, S3, S4, S5, S6, WV\n\t\t- Sentinel-1B: EW, IW, S1, S2, S3, S4, S5, S6, WV\n\t\t- UAVSAR: POL, RPI\n\n- <span style=\"color: #236192; font-size: 20px;\">collectionName</span>\n\t- This keyword is also available through [asf_search](/asf_search/searching/#searching).\n\t- For UAVSAR and AIRSAR data collections only. Search by the mission/campaign name. You may specify a single value. For a list of available collections, refer to the Mission List Endpoint below.\n\t- Example:\n\t\t- UAVSAR: collectionName=ABoVE\n\t\t- AIRSAR: collectionName=collectionName=Akiyoshi,+Japan\n\n- <span style=\"color: #236192; font-size: 20px;\">maxDoppler</span>\n\t- This keyword is also available through [asf_search](/asf_search/searching/#searching).\n\t- Doppler provides an indication of how much the look direction deviates from the ideal perpendicular flight direction acquisition.\n\t- Example:\n\t\t- maxDoppler=1500 or maxDoppler=1500.5\n\n- <span style=\"color: #236192; font-size: 20px;\">minDoppler</span>\n\t- This keyword is also available through [asf_search](/asf_search/searching/#searching).\n\t- Doppler provides an indication of how much the look direction deviates from the ideal perpendicular flight direction acquisition.\n\t- Example:\n\t\t- minDoppler=100 or minDoppler=1500.5\n\n- <span style=\"color: #236192; font-size: 20px;\">maxFaradayRotation</span>\n\t- This keyword is also available through [asf_search](/asf_search/searching/#searching).\n\t- Rotation of the polarization plane of the radar signal impacts imagery. HH and HV signals become mixed. One-way rotations exceeding 5° are likely to significantly reduce the accuracy of geophysical parameter recovery, such as forest biomass.\n\t- Example:\n\t\t- maxFaradayRotation=3.5\n\n- <span style=\"color: #236192; font-size: 20px;\">minFaradayRotation</span>\n\t- This keyword is also available through [asf_search](/asf_search/searching/#searching).\n\t- Rotation of the polarization plane of the radar signal impacts imagery. HH and HV signals become mixed. One-way rotations exceeding 5° are likely to significantly reduce the accuracy of geophysical parameter recovery, such as forest biomass.\n\t- Example:\n\t\t- minFaradayRotation=2\n\n- <span style=\"color: #236192; font-size: 20px;\">flightDirection</span>\n\t- This keyword has constants provided through asf_search. More information can be found [here](/asf_search/searching/#keywords).\n\t- Satellite orbit direction during data acquisition. You may specify a single value.\n\t- Example:\n\t\t- flightDirection=DESCENDING\n\t- Values:\n\t\t- A, ASC, ASCENDING, D, DESC, DESCENDING\n\n- <span style=\"color: #236192; font-size: 20px;\">flightLine</span>\n\t- This keyword is also available through [asf_search](/asf_search/searching/#searching).\n\t- Specify a flightline for UAVSAR or AIRSAR. You may specify a single value.\n\t- Example:\n\t\t- UAVSAR: flightLine=05901\n\t\t- AIRSAR: flightLine=gilmorecreek045-1.93044\n\n- <span style=\"color: #236192; font-size: 20px;\">frame</span>\n\t- This keyword is also available through [asf_search](/asf_search/searching/#searching).\n\t- See also 'asfframe'\n\t- ESA-referenced frames are offered to give users a universal framing convention. Each ESA frame has a corresponding ASF frame assigned. You may specify a single value, range of values, or a list of values.\n\t- Example:\n\t\t- frame=300\n\t\t- frame=300-400\n\t\t- frame=300,303,305\n\t\t- frame=300,303,305-315\n\t- Values:\n\t\t- Any number from 0 to 7200.\n\n- <span style=\"color: #236192; font-size: 20px;\">fullBurstID</span>\n    - Used for Sentinel-1 [burst products](/datasets/using_ASF_data/#sentinel-1-bursts). Each value represents all burst products over a single sub-swath, corresponding to a near-perfect frame-aligned stack. This value is useful for baseline stacking. You may specify a single value, or a list of values.\n    - Example:\n        - single value: fullBurstID=017_034465_IW2\n        - list of values: fullBurstID=017_034465_IW2,079_167884_IW1\n\n- <span style=\"color: #236192; font-size: 20px;\">granule_list</span>\n\t- Comma-separated list of specific scenes (granules). Large lists will need to utilize a [POST request](https://en.wikipedia.org/wiki/POST_(HTTP)).\n\t- granule_list may not be used in conjuction with other keywords, however, it may be used with the output keyword.\n\t- Example:\n\t\t- granule_list=ALPSRP111041130,\n\t\tS1B_IW_GRDH_1SDV_20161124T032008_20161124T032033_003095_005430_9906\n\n- <span style=\"color: #236192; font-size: 20px;\">groupid</span>\n\t- This keyword is also available through [asf_search](/asf_search/searching/#searching).\n\t- Comma-separated list of specific group IDs. For some datasets, the group ID is the same as the scene name. For others, such as Sentinel-1, the group ID is unique for a group of scenes. The group ID value is included in GeoJSON, JSON, and CSV outputs.\n\t- Example:\n\t\t- groupid=S1A_IWDV_0112_0118_037147_150\n\n- <span style=\"color: #236192; font-size: 20px;\">lookDirection</span>\n\t- This keyword is also available through [asf_search](/asf_search/searching/#searching).\n\t- Left or right direction of data acquisition. You may specify a single value.\n\t- Example:\n\t\t- lookDirection=L\n\t- Values:\n\t\t- R, RIGHT, L, LEFT\n\n- <span style=\"color: #236192; font-size: 20px;\">maxInsarStackSize</span>\n\t- An InSAR stack is composed of all SAR granules that cover the same geographic region, are from the same platform, and were acquired with the same beam mode, look angle, and bandwidth. To obtain InSAR stacks containing a certain number of SAR granules specify a min, max, or both.\n\t- Works for ERS-1, ERS-2, JERS, RADARSAT-1, ALOS PALSAR. (Not Sentinel-1)\n\t- Example:\n\t\t- maxInsarStackSize=175\n\n- <span style=\"color: #236192; font-size: 20px;\">minInsarStackSize</span>\n\t- An InSAR stack is composed of all SAR granules that cover the same geographic region, are from the same platform, and were acquired with the same beam mode, look angle, and bandwidth. To obtain InSAR stacks containing a certain number of SAR granules specify a min, max, or both.\n\t- Works for ERS-1, ERS-2, JERS, RADARSAT-1, ALOS PALSAR. (Not Sentinel-1)\n\t- Example:\n\t\t- minInsarStackSize=20\n\n- <span style=\"color: #236192; font-size: 20px;\">offNadirAngle</span>\n\t- This keyword is also available through [asf_search](/asf_search/searching/#searching).\n\t- Off-nadir angles for ALOS PALSAR. You may specify a single value, range of values, or a list of values.\n\t- Example:\n\t\t- offNadirAngle=21.5\n\t\t- offNadirAngle=9.7-14\n\t\t- offNadirAngle=21.5,23.1,20.5-24.2\n\t- Values:\n\t\t- Most common: 21.5, 23.1, 27.1, 34.3\n\t\t- Other: 9.7, 9.9, 13.8, 14, 16.2, 17.3, 17.9, 18, 19.2, 20.5, 21.5, 23.1, 24.2, 24.6, 25.2, 25.8, 25.9, 26.2, 27.1, 28.8, 30.8, 34.3, 36.9, 38.8, 41.5, 43.4, 45.2, 46.6, 47.8, 49, 50, 50.8\n\n- <span style=\"color: #236192; font-size: 20px;\">operaBurstID</span>\n    - Used for [Opera-S1 products](/datasets/using_ASF_data/#opera-sentinel-1). Each value identifies the specific burst for the product. You may specify a single value, or a list of values. \n    - Example:\n        - single value: operaBurstID=T078-165486-IW2\n        - list of values: operaBurstID=T078_165486_IW2, T078_165485_IW2\n\n- <span style=\"color: #236192; font-size: 20px;\">polarization</span>\n\t- This keyword has constants provided through asf_search. More information can be found [here](/asf_search/searching/#keywords).\n\t- A property of SAR electromagnetic waves that can be used to extract meaningful information about surface properties of the earth. You may specify a single value, or a list of values.\n\t- Example:\n\t\t- polarization=VV\n\t\t- polarization=VV,HH\n\t\t- polarization=VV+VH\n\t\t- polarization=Dual+VV\n\t- Values:\n\t\t- AIRSAR: FULL\n\t\t- ALOS: QUADRATURE, HH+5SCAN, HH, HH+4SCAN, VV, HH+3SCAN, FULL, HH+HV, VV+VH\n\t\t- ERS-1: VV\n\t\t- ERS-2: VV\n\t\t- JERS-1: HH\n\t\t- RADARSAT-1: HH\n\t\t- SEASAT: HH\n\t\t- Sentinel-1A: VV, VV+VH, Dual VV, VV+VH, Dual HV, HH, HH+HV, VV, Dual VH\n\t\t- Sentinel-1B: VV, VV+VH, Dual VV, VV+VH, Dual HV, HH, HH+HV, VV, Dual VH\n\t\t- UAVSAR: FULL, HH\n\n- <span style=\"color: #236192; font-size: 20px;\">processingLevel</span>\n\t- This keyword has constants provided through asf_search. More information can be found [here](/asf_search/searching/#keywords).\n\t- Level to which the data has been processed, also type of product. You may specify a single value, or a list of values.\n\t- Example:\n\t\t- processingLevel=L0,L1\n\t- Values:\n\t\t- AIRSAR: 3FP, LTIF, PTIF, CTIF, PSTOKES, DEM, CSTOKES, JPG, LSTOKES\n\t\t- ALOS: L1.0, L1.1, L1.5, L2.2, RTC_LOW_RES, RTC_HI_RES, KMZ\n\t\t- ERS-1: L0, L1\n\t\t- ERS-2: L0, L1\n\t\t- JERS-1: L0, L1\n\t\t- RADARSAT-1: L0, L1\n\t\t- SEASAT: L1,\n\t\t- Sentinel-1A: GRD_HS, GRD_HD, GRD_MS, GRD_MD, GRD_FD, SLC, RAW, OCN, METADATA_RAW, METADATA_SLC, METADATA_GRD_HD, METADATA_GRD_MD, METADATA_GRD_MS, METADATA_GRD_HS, METADATA_OCN\n\t\t- Sentinel-1B: GRD_HS, GRD_HD, GRD_MS, GRD_MD, GRD_FD, SLC, RAW, OCN, METADATA_RAW, METADATA_SLC, METADATA_GRD_HD, METADATA_GRD_MD, METADATA_GRD_MS, METADATA_GRD_HS, METADATA_OCN\n\t\t- Sentinel-1 InSAR: GUNW_STD, GUNW_AMP, GUNW_CON, GUN_COH, GUNW_UNW\n\t\t- SMAP: L1A_Radar_RO_QA, L1A_Radar_RO_HDF5, L1B_S0_LoRes_HDF5, L1B_S0_LoRes_QA, L1B_S0_LoRes_ISO_XML, L1A_Radar_QA, L1A_Radar_RO_ISO_XML, L1C_S0_HiRes_ISO_XML, L1C_S0_HiRes_QA, L1C_S0_HiRes_HDF5, L1A_Radar_HDF5\n\t\t- UAVSAR: KMZ, PROJECTED, PAULI, PROJECTED_ML5X5, STOKES, AMPLITUDE, COMPLEX, DEM_TIFF, PROJECTED_ML3X3, METADATA, AMPLITUDE_GRD, INTERFEROMETRY, INTERFEROMETRY_GRD, INC, SLOPE\n\n- <span style=\"color: #236192; font-size: 20px;\">product_list</span>\n\t- Comma-separated list of specific files (products). Large lists will need to utilize a [POST request](https://en.wikipedia.org/wiki/POST_(HTTP)). You can find the product_list values for any file in the GeoJSON (fileID) or JSON (product_file_id) outputs. It is also available from CMR, in the granuleUR field. It is guaranteed to be a unique indentifier in CMR. You can also find the product_list value in Vertex! See the [Cookbook page](/api/cookbook) for this Tip & more.\n\t- product_list may not be used in conjuction with other keywords, however, it may be used with the output keyword.\n\t- Example:\n\t\t- product_list=ALAV2A276512920,\n\t\tS1A_IW_SLC__1SDV_20210614T154839_20210614T154905_038338_048643_D7E4-SLC\n\n- <span style=\"color: #236192; font-size: 20px;\">relativeOrbit</span>\n\t- This keyword is also available through [asf_search](/asf_search/searching/#searching).\n\t- Path or track of satellite during data acquisition. For UAVSAR it is the [Line ID](https://uavsar.jpl.nasa.gov/cgi-bin/data.pl?_ga=2.201268782.1252483948.1620685771-1930115146.1605056035). You may specify a single value, range of values, or a list of values.\n\t- Example:\n\t\t- relativeOrbit=500,550-580\n\t\t- UAVSAR: relativeOrbit=05905\n\t- Values:\n\t\t- ALOS: 1-671\n\t\t- ERS-1: 0-2410\n\t\t- ERS-2: 0-500\n\t\t- JERS-1: 0-658\n\t\t- RADARSAT-1: 0-342\n\t\t- SEASAT: 1-243\n\t\t- UAVSAR: various\n\n### Geospatial Parameters\n- <span style=\"color: #236192; font-size: 20px;\">bbox</span>\n\t- *Deprecation Notice:* This keyword will be deprecated. Please use 'intersectsWith' instead.\n\t- Bounding boxes define an area using two long/lat points. The Bounding box parameters are 4 comma-separated numbers: lower left longitude,latitude, and upper right longitude,latitude. This is a great choice for very wide search areas.\n\t- Example:\n\t\t- bbox=-150.2,65.0,-150.1,65.5\n\n- <span style=\"color: #236192; font-size: 20px;\">intersectsWith</span>\n\t- This keyword is also available through [asf_search](/asf_search/searching/#searching).\n\t- Search by polygon, a line segment (“linestring”), or a point defined in 2-D Well-Known Text (WKT). Each polygon must be explicitly closed, i.e. the first vertex and the last vertex of each listed polygon must be identical. Coordinate pairs for each vertex are in decimal degrees: longitude is followed by latitude.\n\t- Notes:\n\t\t- Does not support multi-polygon, multi-line or multi-point.\n \t\t- Polygon holes are ignored\n \t\t- This keyword also accepts a [POST request](https://en.wikipedia.org/wiki/POST_(HTTP))\n \t- Example (*Note: The spaces and parentheses below need to be URL encoded first*):\n \t\t- intersectsWith=polygon((-119.543 37.925, -118.443 37.7421, -118.682 36.8525, -119.77 37.0352, -119.543 37.925 ))\n\t\t- intersectsWith=linestring(-119.543 37.925, -118.443 37.7421)\n\t\t- intersectsWith=point(-119.543, 37.925)\n\t- Properly URL encoded:\n\t\t- intersectsWith=point%28-119.543+37.925%29\n\n- <span style=\"color: #236192; font-size: 20px;\">polygon</span>\n\t- *Deprecation Notice:* This keyword will be deprecated. Please use 'intersectsWith' instead.\n\t- Bounding polygon in the digital long/lat format; enter coordinates in counter clockwise direction, repeat the first point at the end to close the polygon: in the format ABCDA\n\t- Example:\n\t\t- polygon=-155.08,65.82,-153.5,61.91,-149.50,63.07,-149.94,64.55,-153.28,64.47,-155.08,65.82\n\n#### Shape Validation\nIf the AOI specified is its own Minimum Bounding Rectangle (MBR) in a mercator projection, the search results returned will instersect with the AOI in a mercator projection, regardless of width. This remains the case even if the international dateline is crossed within the AOI.\n\nIn order for an AOI to be considered its own MBR, it must meet the following criteria:\n\n  - Each vertex shares a latitude or longitude with its neighbors\n  - East/West points share longitude\n  - North/South points share latitude\n\nAOIs that do not fit this criteria will have their points connected along [great circles](https://en.wikipedia.org/wiki/Great_circle).\n\nIn addition, all AOIs are validated, and then simplified as needed. The process for this is:\n \n  1. Validate the input AOI. If it is not valid, an error is displayed.\n  2. Merge overlapping shapes.\n  3. Convex hull.\n  4. Any out-of-range index values are handled by clamping and wrapping them to the valid range of values.\n  5. Simplify points based on proximity threshold. The target is fewer than 400 points.\n\nEach of these steps is performed only when necessary to get the AOI to a single outline with fewer than 400 points. Any unnecessary steps are skipped.\n\n**Examples of validation and simplification:**\n\n- A self-intersecting polygon is provided: \n\t- An error is displayed.\n- A single outline is provided, consisting of 1000 points:\n\t- A simplified version of the same outline is used, consisting of fewer than 400 points.\n- Multiple geometries are provided, all of them overlapping at least in part:\n\t- A single outline is returned, representing the outline of all the shapes combined.\n- Multiple geometries are provided, at least some of them entirely non-overlapping:\n\t- A single outline is returned, representing the convex hull of all the shapes together.\n\n\n### Temporal Parameters\n- <span style=\"color: #236192; font-size: 20px;\">processingDate</span>\n\t- This keyword is also available through [asf_search](/asf_search/searching/#searching).\n\t- Limit results to records that have been processed at ASF since a given date and/or time.\n\t- Example:\n\t\t- processingDate=2017-01-01T00:00:00UTC\n\n- <span style=\"color: #236192; font-size: 20px;\">start</span>\n\t- This keyword is also available through [asf_search](/asf_search/searching/#searching).\n\t- Date of data acquisition. Can be used in combination with 'end'. You may enter natural language dates, or a date and/or time stamp. All times are in UTC. For more information on accepted date formats, see the Date Parser endpoint below.\n\t- Example:\n\t\t- start=May+30,+2018\n\t\t- start=yesterday\n\t\t- start=2010-10-30T11:59:59Z\n\t\t- start=1+week+ago&end=now\n\n- <span style=\"color: #236192; font-size: 20px;\">end</span>\n\t- This keyword is also available through [asf_search](/asf_search/searching/#searching).\n\t- Date of data acquisition. Can be used in combination with 'start'. You may enter natural language dates, or a date and/or time stamp. All times are in UTC. For more information on accepted date formats, see the Date Parser endpoint below.\n\t- Example:\n\t\t- end=May+30,+2018\n\t\t- end=today\n\t\t- end=2021-04-30T11:59:59Z\n\t\t- start=1+week+ago&end=now\n\n- <span style=\"color: #236192; font-size: 20px;\">season</span>\n\t- This keyword is also available through [asf_search](/asf_search/searching/#searching).\n\t- Start and end day of year for desired seasonal range. This keyword may be used in conjunction with start/end to specify a seasonal range within an overall date range. Values are based on the Julian calendar. You must specify both a season start and end date.\n\t- Example:\n\t\t- season=1,31\n\t\t- season=45,67\n\t\t- season=360,10\n\t- Values:\n\t\t- 1 through 365\n\n### Results Parameters\n- <span style=\"color: #236192; font-size: 20px;\">output</span>\n\t- Desired format of the Search API results. If not specified, the default format is metalink. The preferred format is geoJSON.\n\t- Example:\n\t\t- output=geojson\n\t- Values:\n\t\t- geojson, csv, json, kml, metalink, count, download\n\t- Description:\n\t\t- GeoJSON is the preferred output format. If a required field is not included, please contact ASF using the info below or reach the team directly at <uaf-asf-discovery@alaska.edu>\n\t\t- KML can be opened in Google Earth, ArcGIS Earth, or a similar program\n\t\t- Count returns the number of results returned by your query. It does not include any additional information. Using count output can be helpful in determining if your query has returned the correct number of results. There is a time limit on running Search API queries. See the [Troubleshooting page](/api/troubleshooting) for more details.\n\t\t- Metalink provides download information for the scenes returned by your query. It does not include metadata.\n\t\t- Download returns a bulk download script that includes the files returned by the search. See the [Bulk Download documentation](https://asf.alaska.edu/how-to/data-tools/asf-bulk-data-download-options/) for a full guide on using the bulk download script.\n\t\t- JSON includes scene metadata and product URLs. If GeoJSON does not meet your needs, JSON is the preferred format for programmatic use.\n\t\t- CSV also includes scene metadata and product URLs. CSV returns less fields than JSON.\n\n- <span style=\"color: #236192; font-size: 20px;\">maxResults</span>\n\t- This keyword is also available through [asf_search](/asf_search/searching/#searching).\n\t- Maximum number of data records to return from your query.\n\t- Example:\n\t\t- maxResults=10\n\n## Baseline Endpoint\n<https://api.daac.asf.alaska.edu/services/search/baseline>\n\n- <span style=\"color: #236192; font-size: 20px;\">reference</span>\n\t- This is the only mandatory keyword. Input the reference scene name for which you wish to see baseline results.\n\t- Example:\n\t\t- reference=S1B_IW_SLC__1SDV_20210704T135937_20210704T140004_027645_034CB0_4B2C\n\n- <span style=\"color: #236192; font-size: 20px;\">processingLevel</span>\n\t- Level to which the data has been processed. Baseline data is only available for certain processing levels.\n\t- Example:\n\t\t- processingLevel=L1.5\n\t- ProcessingLevel Values Which Contain Baseline Data:\n\t\t- ALOS: L1.1, L1.5; default is L1.1\n\t\t- ERS-1 & ERS-2: L0, L1; default is L0\n\t\t- JERS-1: L0, L1; default is L0\n\t\t- RADARSAT-1: L0, L1; default is L0\n\t\t- Sentinel-1A & Sentinel-1B: SLC\n\n- <span style=\"color: #236192; font-size: 20px;\">output</span>\n\t- Desired format of the Search API results. If not specified, the default format is metalink. The preferred format is geoJSON.\n\t- Example:\n\t\t- output=geojson\n\t- Values:\n\t\t- geojson, csv, json, kml, metalink, count, download\n\t- Description:\n\t\t- GeoJSON is the preferred output format. If a required field is not included, please contact ASF using the info below or reach the team directly at <uaf-asf-discovery@alaska.edu>\n\t\t- KML can be opened in Google Earth, ArcGIS Earth, or a similar program\n\t\t- Count returns the number of results returned by your query. It does not include any additional information. Using count output can be helpful in determining if your query has returned the correct number of results. There is a time limit on running Search API queries. See the [Troubleshooting page](/api/troubleshooting) for more details.\n\t\t- Metalink provides download information for the scenes returned by your query. It does not include metadata.\n\t\t- Download returns a bulk download script that includes the files returned by the search. See the [Bulk Download documentation](https://asf.alaska.edu/how-to/data-tools/data-tools/#bulk_download) for a full guide on using the bulk download script.\n\t\t- JSON includes scene metadata and product URLs. If GeoJSON does not meet your needs, JSON is the preferred format for programmatic use.\n\t\t- CSV also includes scene metadata and product URLs. CSV returns less fields than JSON.\n\n- <span style=\"color: #236192; font-size: 20px;\">maxResults</span>\n\t- Maximum number of data records to return from your query.\n\t- Example:\n\t\t- maxResults=10\n\n## WKT Validation Endpoint\n<https://api.daac.asf.alaska.edu/services/utils/wkt>\n\nThis endpoint will validate and repair a WKT input. The repaired WKT output is how the Search API will interpret the provided WKT input. If a WKT cannot be repaired, it will return an error stating the reason. All validations and errors are returned in JSON format.\n\n- <span style=\"color: #236192; font-size: 20px;\">wkt</span>\n\t- This is the only accepted keyword for this endpoint.\n\t- Example:\n\t\t- wkt=GEOMETRYCOLLECTION(POLYGON((46 -19,30 26,-3 41,22 39,49 16,46 -19)), POLYGON((27 24,12 4,18 31,27 24)))\n\t\t- In this example, the JSON return will list the errors that were repaired, and the final wrapped and unwrapped WKT.\n\n## GeoSpatial Files to WKT Endpoint\n\n<https://api.daac.asf.alaska.edu/services/utils/files_to_wkt>\n\nThis endpoint will accept a [POST request](https://en.wikipedia.org/wiki/POST_(HTTP)) with files attached. It will return the parsed WKT from the file, as well as the repaired wrapped and unwrapped WKT. All outputs are returned in JSON format. The preferred file format is geojson, but the Search API will also support other formats, such as shapefile or kml.\n\nSee the [Tools page](/api/tools) for more details on POST requests.\n\n- Example:\n\t- curl -X POST -F 'files=@/path/to/file' 'https://api.aac.asf.alaska.edu/services/utils/files_to_wkt'\n\n## Date Parser Endpoint\n<https://api.daac.asf.alaska.edu/services/utils/date>\n\nThis endpoint can be used to check how dates are parsed by the Search API. All parsed dates are returned in JSON format.\n\n- <span style=\"color: #236192; font-size: 20px;\">date</span>\n\t- This is the only accepted keyword for this endpoint. You can use natural language, such as \"yesterday\", dates with or without the time stamp, or days of the week.\n\n## Mission List Endpoint\n<https://api.daac.asf.alaska.edu/services/utils/mission_list>\n\nThis endpoint lists all missions (also known as campaigns or collections) for all datasets. Any of the missions returned in the list may be used as a value for the collectionName keyword in the Search endpoint. The mission list is returned in JSON format.\n\n- <span style=\"color: #236192; font-size: 20px;\">platform</span>\n\t- This keyword is optional. If used, it will restrict the list of missions to the specified platform(s).\n\t- Remote sensing platform that acquired the data. Sentinel-1 and ERS have multiple remote sensing platforms, and you may choose whether to specify a specific platform. You may specify a single value, or a list of values.\n\t- Example:\n\t\t- platform=ALOS\n\t\t- platform=SA,SB\n\t\t- platform=S1\n\t- Values:\n\t\t- ALOS, A3, AIRSAR, AS, ERS, ERS-1, E1, ERS-2, E2, JERS-1, J1, RADARSAT-1, R1, SEASAT, SS, S1, Sentinel, Sentinel-1, Sentinel-1A, SA, Sentinel-1B, Sentinel-1 Interferogram (BETA), SB, SMAP, SP, UAVSAR, UA\n\n## Health Endpoint\n<https://api.daac.asf.alaska.edu/health>\n\nThis endpoint is used to check the Search API health. It is returned in JSON format. There are no keywords associated with the health check endpoint.\n\nIn addition to Search API health, it also returns Search API configs and CMR health status.\n",
  "L10_P_1": "##L1.0 Products\nThis product is generated from the raw observation data (Level 0) through data editing such as bit realignment and the addition of orbit information. It is reconstructed, unprocessed signal data with radiometric and geometric correction coefficients (appended, but not applied).\n\n##L1.1 Products\nThis product is generated from Single Look Complex (SLC) products equally spaced on slant range (equal to the spacing of sampling measurement), generated after rendering SAR processing to a level 1.0 product. These products are compressed in range and azimuth. Amplitude and phase information are preserved. Individual files are provided for each polarization for multi-polarization modes.\n\n##L1.5 Products\nThis product is generated from Multi-look amplitude images projected onto map coordinates (geo-referenced). This is rendered from SAR processing to level 1.0 products, and is acquired in single polarization high resolution mode. These products may be visualized without further processing. Individual files are provided for each polarization for multi-polarization modes.\n\n##KMZ Products\nThis product is a compressed file that includes a KML file and a color browse image (PNG) file. The KMZ can be uncompressed by changing the .kmz file extension to .zip and unzipping it.\n\nYou may view the .kmz in Google Earth, or a similar program. Once unzipped, the .kml file can also be viewed in Google Earth. Opened in Google Earth, the file displays in an outline of the scene footprint on the Earth, and includes areas of no data, and a color browse of the geocorrected image in its correct orientation within the outline. The .png file is geocoded and rotated into projected space.\n\n##Low-Res and Hi-Res Terrain Corrected Products\nThe terrain correction products are generated for all FBS, FBD, and PLR beam modes, and include all available beam modes for dual-pol and qual-pol data. Any wide-beam data, as well as direct downlink direct source network (DSN) data, acquired by ASF at reduced resolution, are not terrain corrected.\n\nThe terrain corrected products are derived from ALOS PALSAR Level 1.1 single look complex data, generated by the JAXA Sigma SAR processor (version 12.01) of the ALOS core software (release 6.07).\n\nRTC products are distributed at two resolutions. The hi-res products have a pixel size of 12.5m and are generated from high-resolution (NED13) and mid-resolution (SRTM 30m, NED1, and NED2) DEMs. The low-res products are generated at a 30m level for all available DEMs. All products are terrain corrected at the native pixel size of the DEM that is used for the correction. No additional resampling is required. All RTC products are geocoded to the Universal Transverse Mercator (UTM) projection and provided as floating-point power values in GeoTIFF format. The reference for the RTC products is pixel as point.\n\n##Further Reading\n- [DEM Information](https://asf.alaska.edu/information/palsar-rtc-dem-information/)\n- [Level 1.0 Product Format Description](http://www.ga.gov.au/__data/assets/pdf_file/0019/11719/GA10287.pdf)\n- [Level 1.1/1.5 Product Format Description](https://www.eorc.jaxa.jp/ALOS/en/doc/fdata/PALSAR_x_Format_EL.pdf)\n- [USGS ALOS PALSAR Radar Processing System](https://www.usgs.gov/centers/eros/science/usgs-eros-archive-radar-alos-palsar-radar-processing-system?qt-science_center_objects=0#qt-science_center_objects)\n- [What is a KMZ File?](https://developers.google.com/kml/documentation/kmzarchives)\n- [Difference between KML and KMZ](https://whyisdifference.com/technology/software-technology/difference-between-kml-and-kmz.html)\n- [RTC Product Guide](https://asf.alaska.edu/wp-content/uploads/2019/03/rtc_product_guide_v1.2.pdf)\n- [RTC Algorithm Technical Basis Document](https://asf.alaska.edu/wp-content/uploads/2019/03/rtc_atbd_v1.2_final.pdf)\n- [Product Format Specification](https://asf.alaska.edu/wp-content/uploads/2019/03/rtc_product_specification_v1.1.pdf)\n\n\n\n\n\n",
  "OVERVIEW_1": "## Overview\nRadar remote sensing has become a highly important data source in the Geosciences. This is mostly due to the ability of radar to penetrate clouds and operate independently of solar illumination. In addition radar sensors benefit from their ability to easily identify changes, track surface deformation with cm-accuracy, and map large areas regularly and over long time scales. It is not surprising that radar remote sensing is regularly used for studying earthquakes, volcanoes, and glaciers, as well as for the monitoring of anthropogenic activities such as hydrocarbon extraction, and groundwater pumping.\n\nWithin the SARVIEWS project, we are working on harnessing the capabilities of SAR by developing a fully automatic processing system that produces value-added products in support of monitoring natural disasters. The SARVIEWS processor is implemented in the Amazon Cloud and utilizes modern processing technology to generate geocoded and fully terrain corrected image time series, as well as interferometric SAR data over areas affected by natural disasters. To facilitate full automation, the SARVIEWS processing flow is triggered automatically by existing hazard alert systems such as the [USGS Earthquake Notification Service](https://earthquake.usgs.gov/ens/). Currently, SARVIEWS is supporting hazards related to volcanic eruptions and earthquakes. The inclusion of flood events is in preparation.\n\n## Hazard Monitoring Criteria\n\nSARVIEWS subscriptions are created in near real-time based upon reports from monitoring organizations such as the USGS and the Smithsonian Institution Global Volcanism Program. Subscriptions are created automatically after checking [Earthquake Notification Service (ENS)](https://earthquake.usgs.gov/ens/) emails and [Volcano Notification Service (VNS)](https://volcanoes.usgs.gov/vns2/) emails, or the Smithsonian Institution Global Volcanism Program's weekly updates for active volcanoes outside the United States.\n\n### Earthquakes\n\nEarthquake subscriptions are created if the earthquake event has potential surface deformation, which is roughly assesed based upon the following logic:\n\n<table>\n  <thead>\n    <tr>\n      <th>Magnitude</th>\n      <th>Shallow: 0-35 km</th>\n      <th>Medium: 35-100 km</th>\n      <th>Deep: 100+ km</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>Large: Mag 7.5+</td>\n      <td>Yes</td>\n      <td>Yes</td>\n      <td>Yes</td>\n    </tr>\n    <tr>\n      <td>Medium: Mag 7.0 - 7.5</td>\n      <td>If within 75 km of coast</td>\n      <td>If within 25 km of coast</td>\n      <td>No</td>\n    </tr>\n    <tr>\n      <td>Small: Mag 6.0 - 7.0</td>\n      <td>If within 25 km of coast</td>\n      <td>If within 0.5 km of coast</td>\n      <td>No</td>\n    </tr>\n  </tbody>\n</table>\n\nThese criteria provide a quick estimate of the strength of the earthquake in relation to depth and the distance from land in order to limit event subscriptions to only those with the potential for surface deformation. This simple logic is created upon the ENS email, and does not wait for more data to calculate surface deformation with conventional seismologic methods. Once created, earthquake subscriptions process Sentinel data for 6 months from the date of the earthquake.\n\n### Volcanoes\n\nCriteria for volcano subscriptions reply on the VNS Activity Notice emails for domestic volcanoes, and the Smithsonian Institution Global Volcanism Program's RSS feed for international volcanoes. If a volcano is flagged as a WARNING Alert level, or a RED aviation code, a subscription is created for the volcano. Globally, if the volcano's activity is high enough to be triggered and posted by the Global Volcanism Program, SARVIEWS creates a subscription. Volcano subscriptions process data starting 1 year prior to the activity, and continue indefinitely until volcano activity levels return to normal.\n\n## On Demand Processing\n\nThe SARVIEWS processor takes full advantage of the extensive SAR archives available at the Alaska Satellite Facility (ASF), NASA Distributed Active Archive Center (DAAC) for Synthetic Aperture Radar data. Through ASF, SARVIEWS has efficient access to the historic and future acquisitions of the Sentinel-1 sensors, a spaceborne SAR system launched and operated by the European Space Agency. Sentinel-1 images all of Earth’s landmasses every 6 - 12 days, providing valuable data for hazard monitoring.\n\nTo efficiently access and process the incoming stream of Sentinel-1 SAR data, SARVIEWS leverages ASF HyP3, a cloud-based processing system that generates value-added SAR products on demand. On demand processing via HyP3 is also available from [ASF's Vertex](https://search.asf.alaska.edu/#/?topic=onDemand). Through HyP3, SARVIEWS has full access to the benefits of the cloud, such as elastic scaling of compute resources and efficient cloud-based storage and distribution. For more information, please visit the [HyP3 Documentation](https://hyp3-docs.asf.alaska.edu/).\n\n## FAQ\n\n**Is SARVIEWS free?**\n\nAll of the SARVIEWS products available in Vertex are freely available for download and use without restrictions. These are value-added products created from freely available Sentinel-1 data, with no login necessary. Please credit both ESA and SARVIEWS when using our data.\n\n**How do I bulk download products?**\n\nWhen you choose to copy the URLs for any event products, you will get a list of links to all of the selected SARVIEWS products. You may paste these links into a file, such as a .csv. To download the products, use a program such as wget with the '-i' option. For example:\n\n    ## move to the location you want the products to be downloaded\n    cd path/to/destination\n\n    ## download with the -i option to specify the .csv\n    wget -i path/to/download_all.csv\n\nYou may also download and run the Python Bulk Download script to download your selected event products.\n\n**When will the next product become available?**\n\nSARVIEWS automatically creates and archives products as soon as they become available. If a product is missing for a subscrciption, it means that the subscription is waiting on a new scene to be acquired, or it's still processing. Generally, there are 12 days between most Sentinel overpasses.\n\n**What software is used to process SARVIEWS data?**\n\nSARVIEWS events are processed using [GAMMA Remote Sensing](https://www.gamma-rs.ch/software) software tools through the ASF HyP3 engine. For more information on algoritm specifics, please visit the [ASF HyP3 products page](https://hyp3-docs.asf.alaska.edu/products/).\n\n## Acknowledgements & Contact\n\nThe SARVIEWS effort was funded by the [NASA Applied Sciences Disasters Program](https://appliedsciences.nasa.gov/what-we-do/disasters) through grant NNX12AQ38G. Sentinel-1 data is provided by the European Space Agency through their [Copernicus](https://www.esa.int/Applications/Observing_the_Earth/Copernicus) program. Access to Sentinel-1 data is provided by the [NASA Alaska Satellite Facility (ASF) DAAC](https://asf.alaska.edu/). SARVIEWS products contain modified Copernicus Sentinel data. Contributions to SARVIEWS were made by the SARVIEWS project team including FJ Meyer, S Arko, JB Nicoll, K Hogenson, W Gong, DB McAlpin, P Webley and many more. We owe thanks to the ASF Advanced Prototype Development (APD) and ASF HyP3 teams for supporting the robust implementation of SARVIEWS procedures and for their assistance with moving SARVIEWS into the cloud. Ongoing contributions are being made by the many beta-testers of our service.\n\nFor more information on SARVIEWS, please contact [Franz Meyer](mailto:fjmeyer@alaska.edu). You may also view the [Twitter](https://twitter.com/SARevangelist?) account.\n\n## Useful Links\n\n- The University of Alaska Fairbanks' (UAF) Microwave Remote Sensing class: [UAF GEOS 657](https://radar.community.uaf.edu/)\n- Newcastle University's Generic Atmospheric Correction Online Service for InSAR: [GACOS](http://www.gacos.net/)\n- The German Aerospace Center (DLR) for Satellite Based Crisis Information: [DLR ZKI](https://www.dlr.de/eoc/desktopdefault.aspx/tabid-12797#gallery/36755)\n- NASA's Jet Propulsion Laboratory's Advanced Rapid Imaging and Analysis (ARIA) Center for Natural Hazards: [JPL ARIA](https://aria.jpl.nasa.gov/)\n- ESA's Copernicus Emergency Management Service: [Copernicus EMS](https://emergency.copernicus.eu/)\n- The Center for Observation and Modelling of Earthquakes, Volcanoes and Tectonics: [COMET InSAR](https://comet.nerc.ac.uk/earth-observation/insar/)\n- ESA's Thematic Exploitation Platforms: [ESA TEPs](https://tep.eo.esa.int/home)\n\n",
  "SBAS_1": "# SBAS Search Type\n\n## What is SBAS?\nSBAS is an acronym for **short baseline subsets**. It is a technique used in interferometry. The Vertex SBAS tool provides perpendicular and temporal baseline data, as well as scene pairs, for a chosen reference scene.\n\n## What are some uses for SBAS?\nSBAS is widely used in the geosciences community. It works best for natural environments over a large scale and can be used to look at gradual change over time. SBAS requires input of a series of interferograms and the final output is a time series showing motion.\n\nOne advantage of SBAS is that you are not restricted to a single interferogram. You can see gradual changes over time. It can also be useful for older datasets which sometimes have irregular acquisitions. The temporal and spatial filtering can help increase the accuracy for measuring deformation.\n\nYou must choose which interferograms to use, which can require some experimentation. The Vertex SBAS tool simplifies this by providing good visualization and making it easier for you to quickly determine which scenes to use.\n\nThere are other preferred approaches for urban environments, or higher resolution needs. However, regardless of your analysis needs, the SBAS tool is a useful overview tool and can also be used as a 2-D baseline plot. It gives a comprehensive, but rapid visualization of scenes.\n\nFurther reading on baseline, including descriptions of multiple approaches, can be found [here](https://www.sciencedirect.com/science/article/pii/S0924271615002415). A case study comparison of PS and SBAS can be found [here](https://ieeexplore.ieee.org/document/5692806).\n\n## How to use Vertex SBAS Tool\nVisit **[ASF's Vertex](https://search.asf.alaska.edu)** to begin using the SBAS tool.\n![type:video](https://www.youtube.com/embed/bQPdtuobdcg)\n\n### **Beginning your SBAS Search**\n\n- If you do not have a particular reference scene chosen, you can search for scenes using the geographic or list search. The center column will have a button under the metadata titled ***SBAS Tool*** for any scenes that are eligible. You may click this button to be directed to an SBAS search. The SBAS search will use the chosen scene as the reference scene.\n\n- If you do have a particular reference scene chosen, you can select ***SBAS*** from the Search Type dropdown list. You may enter your reference scene and hit ***Search***.\n\n### **Interacting with SBAS Search Results**\nWhile in SBAS Search type, you will notice many familiar controls in the results panel. The pairs are shown in the left column. The center column lists the metadata for the two endpoints of the selected pair. The SBAS Chart is shown in the right column.\n\n**Result Panel Controls**\n\n- At the top left of the results panel, you will see the number of pairs listed.\n- **Zoom** will *Zoom to results* magnifying the map area of the Earth where the scenes are located.\n- **Queue** will *Add all to Downloads* allowing you to add all scenes to the download queue.\n- **On Demand** will allow you to *Add all to On Demand queue* to perform custom processing on the scenes. You may also choose to *Create Subscription*.\n\t- You may choose from **RTC GAMMA**, **InSAR GAMMA**, or **autoRIFT**, depending on your needs. RTC GAMMA processing is performed on the individual scenes in your result set. InSAR GAMMA and autoRIFT processing are performed on the pairs in your result set.\n\t- **Note:** Currently, only scenes with beam mode IW are eligible for On Demand processing.\n- **Pairs** will *Download Pair CSV* which lists the scenes in each pair and the download URL for each. It also includes the baseline values.\n- In the left column, highlight the desired pair and click the **On Demand** icon to *Add pair to On Demand queue*. You may choose *InSAR GAMMA* or *autoRIFT* processing for each pair you wish to add.\n\n**Chart Controls**\n\n- The dots on the chart represent individual scenes. Hovering over them will list their temporal and perpendicular information. The lines represent the pairs.\n- You may use the mouse to navigate the chart. There are **Zoom In** and **Zoom Out** buttons located above the chart. The **Zoom to Fit** button will fit all of the pairs into the visible chart.\n- You may click on any pair line in the chart. When you do, the selected pair is highlighted in red and the metadata for that pair is shown in the center column.\n- You may adjust the temporal and perpendicular baseline using the sliders on the chart.\n- You may also create your own pair if desired:\n\t1. Under **Custom Pair**, click the **Plus symbol** to *Start adding custom pair*.\n\t7. Click the dot on the chart representing the first scene.\n\t2. Click the dot on the chart representing the second scene.\n\t3. The new pair is created, and the pair detail is added to the bottom of the result list. Manually added pairs will be displayed with a dotted line on the chart.\n\t4. **Note:** You may also add custom pairs to the On Demand queue.\n- If you wish to stop adding a pair after you have begun, you may click the **Square symbol** to *Stop adding custom pair*.\n- If you wish to delete an added pair, you may click on the dotted pair line and click the **Minus symbol** to *Remove custom pair*. Note that only manually added pairs may be deleted.\n\n#### Gaps Detected Warning Message\n\nIf there are gaps detected in your SBAS pairs, a warning message will be displayed. It is recommended to avoid disconnected InSAR pair networks. Disconnected pair networks make it difficult to create unbiased estimates of InSAR velocities within a time-series analysis. \n\nIf you wish to eliminate the gaps, you may modify your search filters, such as increasing the temporal baseline until all scenes are connected. You may also add manual pairs for the missing connections. Once all scenes have at least one connection, the warning message will disappear. \n\n#### SBAS Criteria\n\n- Click **SBAS Criteria...** for additional filtering options.\n\t- You may enter a **Start** or **End** date, or select dates on the calendar.\n\t- **Seasonal Search** allows constraining the results to certain annual periods within an overall range of dates.  Click the Seasonal Search toggle and additional options will appear, allowing you to adjust the sliders to specify a seasonal range (*Season Start Day/Season End Day*).\n\t- **Latitudinal Overlap** allows you to set the overlap threshold for pairs. Filtering out non-overlapping pairs can reduce errors in On Demand InSAR processing.\n\t\t- **No Overlap Threshold** is the default. All pair results are returned, including any non-overlapping pairs.\n\t\t- **Any Overlap Threshold** will ensure that all pairs have some overlap. Any non-overlapping pairs will be filtered out of the results.\n\t\t- **50% Overlap Threshold** ensures that all pairs have approximately 50% overlap. Any pairs with less overlap will be filtered out of the results.\n\n## Next Steps\nThe next step is creating interferograms. You may do this through On Demand processing in Vertex. First, you would add some or all of the pairs to the On Demand queue as InSAR jobs. In the queue, there are limited options available for customizing your InSAR processing. You may also specify a project name. Submit the queue when you have selected all desired options. When the interferograms are completed, you can view and download them by using the On Demand Products search type in Vertex.\n\nFor areas with glacial ice, autoRIFT is another processing option. Similar to InSAR, you would add some or all pairs to the On Demand queue as autoRIFT jobs. There are no additional customization options available for autoRIFT processing, however you can still specify a project name. When autoRIFT processing is completed, you can view and download the products by using the On Demand Products search type in Vertex.\n\nMore detail can be found in the [Vertex User Guide](/vertex/manual). Help documentation, including videos, is also available in Vertex [here](https://search.asf.alaska.edu/#/?maxResults=250&topic=onDemand).\n\nTo learn more, you may also see the [On Demand documentation](https://hyp3-docs.asf.alaska.edu/).\n",
  "SEARCH_API_BASIC_1": "# Search API Basics\n\nBuilding a Search API query consists of 3 basic steps:\n\n1. Use the Search API base URL: https://api.daac.asf.alaska.edu\n2. Pick an endpoint. All available endpoints are listed in the [Keywords documentation](/api/keywords). The Search endpoint uses this base URL: https://api.daac.asf.alaska.edu/services/search/param\n3. Build your query using [keywords](/api/keywords)\n\nThe completed URL will be in this format: https://api.daac.asf.alaska.edu/services/search/param?keyword1=value1&keyword2=value2,value3&keyword3=value4-6\n\nOnce your query is built, you may execute by copy/pasting into a browser window, a command line interface, or by using a program. More details on various options and some syntax tips can be found in the [Search API Tools documentation](/api/tools).\n\n**Downloading Data**\n\nIn order to download data, you will need a NASA EOSDIS Earthdata Login account. Earthdata accounts are free. Go to [Earthdata Login — Create Profile](https://urs.earthdata.nasa.gov/users/new) to create an account.\n\nYou will be prompted to accept the ASF End-User License Agreement and set a Study Area to complete your new user setup.\n\n*Note: A research agreement is required for access to JERS-1 and RADARSAT-1 data. Please complete the required [Research Agreement](https://asf.alaska.edu/restricted-data-access-request), or contact user support at the email or number below.*\n\n**Next Steps**\n\nSee [Search API Keywords](/api/keywords) to get started on building a query, or see the [Tools page](/api/tools) for some examples.\n\nAlternatively, you may wish to use asf_search, a Python module for performing searches of the ASF catalog. It also offers baseline functionality and download support. Additionally, numerous constants are provided to ease the search process. It is available through PyPi and Conda. More information can be found [here](/asf_search/basics).\n",
  "SEARCHING_1": "# Searching\n\nEach search function returns an ```ASFSearchResults``` object:\n\n- ```geo_search()``` Find product info over an area of interest using a WKT string\n- ```granule_search()``` Find product info using a list of scene names\n- ```product_search()``` Find product info using a list of product IDs\n- ```stack_from_id()``` Find a baseline stack of products using a reference scene ID\n- If the above search approaches do not meet your search needs, ```search()``` supports all available keywords:\n    - ```search()``` Find product info using any combination combination of search parameters. See the keywords list below.\n\nExamples of some search workflows can be found in this [sample script](https://github.com/asfadmin/Discovery-asf_search/blob/master/examples/hello_world.py). You may also reference the [Jupyter notebooks](https://github.com/asfadmin/Discovery-asf_search/tree/master/examples) for example workflows.\n\nFor more advanced usage, see sections [ASFSearchResults class](/asf_search/ASFSearchResults/) and [ASFProduct class](/asf_search/ASFProduct).\n\n## Keywords\n\nKeywords are used to find the desired data. Use as many or as few keywords as needed. Available keywords and descriptions are listed below. Additionally, numerous constants are provided to ease the search process. Currently, we provide constants for beam mode, flight direction, instrument, platform, polarization, and product type. You can see the full [list of constants here](https://github.com/asfadmin/Discovery-asf_search/tree/master/asf_search/constants).\n\n### Dataset Parameters\n- <span style=\"color: #236192; font-size: 20px;\">platform</span>\n    - See the [list of constants](https://github.com/asfadmin/Discovery-asf_search/blob/master/asf_search/constants/PLATFORM.py)\n    - Remote sensing platform that acquired the data. Sentinel-1 and ERS have multiple remote sensing platforms, and you may choose whether to specify a specific platform. You may specify a single value, or a list of values.\n    - You may also get the available list of constants by using ```help(asf_search.constants.PLATFORM)```\n    - Example:\n        - platform=asf.PLATFORM.SENTINEL1A\n\n- <span style=\"color: #236192; font-size: 20px;\">instrument</span>\n    - See the [list of constants](https://github.com/asfadmin/Discovery-asf_search/blob/master/asf_search/constants/INSTRUMENT.py)\n    - Remote sensing instrument that acquired the data. For some platforms, such as ALOS, there are multiple instruments to choose from.\n    - You may also get the available list of constants by using ```help(asf_search.constants.INSTRUMENT)```\n    - Example:\n        - instrument=asf.INSTRUMENT.AVNIR_2\n\n- <span style=\"color: #236192; font-size: 20px;\">absoluteBurstID</span>\n    - Used for Sentinel-1 [burst products](/datasets/using_ASF_data/#sentinel-1-bursts). Each value identifies the stack of a burst cycle, representing all products generated over a specific sub-swath. You may specify a single value, or a list of values. \n    - Example:\n        - single value: absoluteBurstID='102563902'\n        - list of values: absoluteBurstID=['102563902', '103558145']\n\n- <span style=\"color: #236192; font-size: 20px; font-size: 20px;\">absoluteOrbit</span>\n    - For ALOS, ERS-1, ERS-2, JERS-1, RADARSAT-1, Sentinel-1A, and Sentinel-1B this value corresponds to the orbit count within the orbit cycle. For UAVSAR it is the [Flight ID](https://uavsar.jpl.nasa.gov/cgi-bin/data.pl?_ga=2.34282209.1335434931.1620087198-1930115146.1605056035). You may specify a single value, range of values, or a list of values.\n    - Example:\n        - single value: absoluteOrbit=25436\n        - range of values: absoluteOrbit=(12005, 12008)\n        - list of values: absoluteOrbit=[25436, 25450]  \n\n- <span style=\"color: #236192; font-size: 20px;\">asfFrame</span>\n    - See also 'frame'\n    - This is primarily an ASF / [JAXA](https://global.jaxa.jp/) frame reference. However, some platforms use other conventions. You may specify a single value, range of values, or a list of values.\n    - Example:\n        - single value: asfFrame=300\n        - range of values: asfFrame=(2845, 2855)\n        - list of values: asfFrame=[2800, 2845]\n    - Values:\n        - ERS, JERS, RADARSAT: ASF frames 0 to 900\n        - ALOS PALSAR: JAXA frames 0 to 7200\n        - SEASAT: ESA-like frames 208 to 3458\n        - Sentinel-1: In-house values 0 to 1184\n\n- <span style=\"color: #236192; font-size: 20px;\">beamMode</span>\n    - See the [list of constants](https://github.com/asfadmin/Discovery-asf_search/blob/master/asf_search/constants/BEAMMODE.py)\n    - The beam mode used to acquire the data.\n    - You may also get the available list of constants by using ```help(asf_search.constants.BEAMMODE)```\n    - Example:\n        - beamMode=asf.BEAMMODE.POL\n\n- <span style=\"color: #236192; font-size: 20px;\">beamSwath</span>\n    - The beam swath encompasses a look angle and beam mode. You may specify a single value, or a list of values.\n    - Example:\n        - single value: beamSwath='IW'\n        - list of values: beamSwath=['IW','EW']\n\n- <span style=\"color: #236192; font-size: 20px;\">campaign</span>\n    - For UAVSAR, AIRSAR, and Sentinel-1 Interferogram datasets only. Search by the campaign name. You may specify a single value.\n    - For a list of available campaigns, use the ```asf_search.campaigns()``` function. You must provide the desired platform.\n        - ```asf_search.campaigns(asf_search.PLATFORM.UAVSAR)```\n    - Example:\n        - campaign='Purace Volcano, Colombia'\n\n- <span style=\"color: #236192; font-size: 20px;\">maxDoppler</span>\n    - Doppler provides an indication of how much the look direction deviates from the ideal perpendicular flight direction acquisition.\n    - Example:\n        - maxDoppler=1500 or maxDoppler=1500.5\n\n- <span style=\"color: #236192; font-size: 20px;\">minDoppler</span>\n    - Doppler provides an indication of how much the look direction deviates from the ideal perpendicular flight direction acquisition.\n    - Example:\n        - minDoppler=100 or minDoppler=1500.5\n\n- <span style=\"color: #236192; font-size: 20px;\">maxFaradayRotation</span>\n    - Rotation of the polarization plane of the radar signal impacts imagery. HH and HV signals become mixed. One-way rotations exceeding 5° are likely to significantly reduce the accuracy of geophysical parameter recovery, such as forest biomass.\n    - Example:\n        - maxFaradayRotation=3.5\n\n- <span style=\"color: #236192; font-size: 20px;\">minFaradayRotation</span>\n    - Rotation of the polarization plane of the radar signal impacts imagery. HH and HV signals become mixed. One-way rotations exceeding 5° are likely to significantly reduce the accuracy of geophysical parameter recovery, such as forest biomass.\n    - Example:\n        - minFaradayRotation=2\n\n- <span style=\"color: #236192; font-size: 20px;\">flightDirection</span>\n    - See the [list of constants](https://github.com/asfadmin/Discovery-asf_search/blob/master/asf_search/constants/FLIGHT_DIRECTION.py)\n    - Satellite orbit direction during data acquisition. You may specify a single value.\n    - You may also get the available list of constants by using ```help(asf_search.constants.FLIGHT_DIRECTION)```\n    - Example:\n        - flightDirection=asf.FLIGHT_DIRECTION.ASCENDING\n\n- <span style=\"color: #236192; font-size: 20px;\">flightLine</span>\n    - Specify a flightline for UAVSAR or AIRSAR. You may specify a single value.\n    - Example:\n        - UAVSAR: flightLine='05901'\n        - AIRSAR: flightLine='gilmorecreek045-1.93044'\n\n- <span style=\"color: #236192; font-size: 20px;\">frame</span>\n    - See also 'asfFrame'\n    - ESA-referenced frames are offered to give users a universal framing convention. Each ESA frame has a corresponding ASF frame assigned. You may specify a single value, range of values, or a list of values.\n    - Example:\n        - single value: frame=300\n        - range of values: frame=(305, 315)\n        - list of values: frame=[300, 303, 305]\n    - Values:\n        - Any number from 0 to 7200.\n\n- <span style=\"color: #236192; font-size: 20px;\">fullBurstID</span>\n    - Used for Sentinel-1 [burst products](/datasets/using_ASF_data/#sentinel-1-bursts). Each value represents all burst products over a single sub-swath, corresponding to a near-perfect frame-aligned stack. This value is useful for baseline stacking. You may specify a single value, or a list of values.\n    - Example:\n        - single value: fullBurstID='017_034465_IW2'\n        - list of values: fullBurstID=['017_034465_IW2', '079_167884_IW1']\n\n- <span style=\"color: #236192; font-size: 20px;\">groupID</span>\n    - List of specific group IDs. For some datasets, the group ID is the same as the scene name. For others, such as Sentinel-1, the group ID is unique for a group of scenes.\n    - Example:\n        - groupID='S1A_IWDV_0112_0118_037147_150'\n\n- <span style=\"color: #236192; font-size: 20px;\">lookDirection</span>\n    - Left or right direction of data acquisition. You may specify a single value.\n    - Example:\n        - lookDirection='L'\n    - Values:\n        - R, RIGHT, L, LEFT\n\n- <span style=\"color: #236192; font-size: 20px;\">offNadirAngle</span>\n    - Off-nadir angles for ALOS PALSAR. You may specify a single value, range of values, or a list of values.\n    - Example:\n        - single value: offNadirAngle=21.5\n        - range of values: offNadirAngle=(9.7, 14)\n        - list of values: offNadirAngle=[21.5, 23.1]\n    - Values:\n        - Most common: 21.5, 23.1, 27.1, 34.3\n        - Other: 9.7, 9.9, 13.8, 14, 16.2, 17.3, 17.9, 18, 19.2, 20.5, 21.5, 23.1, 24.2, 24.6, 25.2, 25.8, 25.9, 26.2, 27.1, 28.8, 30.8, 34.3, 36.9, 38.8, 41.5, 43.4, 45.2, 46.6, 47.8, 49, 50, 50.8\n\n- <span style=\"color: #236192; font-size: 20px;\">operaBurstID</span>\n    - Used for [Opera-S1 products](/datasets/using_ASF_data/#opera-sentinel-1). Each value identifies the specific burst for the product. You may specify a single value, or a list of values. \n    - Example:\n        - single value: operaBurstID='T078-165486-IW2'\n        - list of values: operaBurstID=['T078_165486_IW2', 'T078_165485_IW2']\n\n- <span style=\"color: #236192; font-size: 20px;\">polarization</span>\n    - See the [list of constants](https://github.com/asfadmin/Discovery-asf_search/blob/master/asf_search/constants/POLARIZATION.py)\n    - A property of SAR electromagnetic waves that can be used to extract meaningful information about surface properties of the earth. You may specify a single value, or a list of values.\n    - You may also get the available list of constants by using ```help(asf_search.constants.POLARIZATION)```\n    - Example:\n        - polarization=asf.POLARIZATION.VV\n\n- <span style=\"color: #236192; font-size: 20px;\">processingLevel</span>\n    - See the [list of constants](https://github.com/asfadmin/Discovery-asf_search/blob/master/asf_search/constants/PRODUCT_TYPE.py)\n    - Level to which the data has been processed, also type of product.\n    - You may also get the available list of constants by using ```help(asf_search.constants.PRODUCT_TYPE)```\n    - Example:\n        - processingLevel=asf.PRODUCT_TYPE.SLC\n\n- <span style=\"color: #236192; font-size: 20px;\">relativeBurstID</span>\n    - Used for Sentinel-1 [burst products](/datasets/using_ASF_data/#sentinel-1-bursts). Each value identifies a burst cycle, and within each sub-swath these values are unique. You may specify a single value, or a list of values.\n    - Example:\n        - single value: relativeBurstID='367299'\n        - list of values: relativeBurstID=['167877', '167882']\n\n- <span style=\"color: #236192; font-size: 20px;\">relativeOrbit</span>\n    - Path or track of satellite during data acquisition. For UAVSAR it is the [Line ID](https://uavsar.jpl.nasa.gov/cgi-bin/data.pl?_ga=2.201268782.1252483948.1620685771-1930115146.1605056035). You may specify a single value, range of values, or a list of values.\n    - Example:\n        - single value: relativeOrbit=5905\n        - range of values: relativeOrbit=(2400, 2410)\n        - list of values: relativeOrbit=[500, 580]\n    - Values:\n        - ALOS: 1-671\n        - ERS-1: 0-2410\n        - ERS-2: 0-500\n        - JERS-1: 0-658\n        - RADARSAT-1: 0-342\n        - SEASAT: 1-243\n        - UAVSAR: various\n\n### Geospatial Parameters\n\n- <span style=\"color: #236192; font-size: 20px;\">intersectsWith</span>\n    - Search by polygon, a line segment (“linestring”), or a point defined in 2-D Well-Known Text (WKT). Each polygon must be explicitly closed, i.e. the first vertex and the last vertex of each listed polygon must be identical. Coordinate pairs for each vertex are in decimal degrees: longitude is followed by latitude.\n    - Example:\n        - intersectsWith='POLYGON((-152.81 58.49,-154.90 57.49,-155.08 56.30,-153.82 56.34,-151.99 57.30,-151.43 58.19,-152.81 58.49))'\n        - intersectsWith='LINESTRING(-119.543 37.925, -118.443 37.7421)'\n        - intersectsWith='POINT(-119.543 37.925)'\n\n#### Shape Validation\nIf the AOI specified is its own Minimum Bounding Rectangle (MBR) in a mercator projection, the search results returned will instersect with the AOI in a mercator projection, regardless of width. This remains the case even if the international dateline is crossed within the AOI.\n\nIn order for an AOI to be considered its own MBR, it must meet the following criteria:\n\n  - Each vertex shares a latitude or longitude with its neighbors\n  - East/West points share longitude\n  - North/South points share latitude\n\nAOIs that do not fit this criteria will have their points connected along [great circles](https://en.wikipedia.org/wiki/Great_circle).\n\nIn addition, all AOIs are validated, and then simplified as needed. The process for this is:\n \n  1. Validate the input AOI. If it is not valid, an error is displayed.\n  2. Merge overlapping shapes.\n  3. Convex hull.\n  4. Any out-of-range index values are handled by clamping and wrapping them to the valid range of values.\n  5. Simplify points based on proximity threshold. The target is fewer than 400 points.\n\nEach of these steps is performed only when necessary to get the AOI to a single outline with fewer than 400 points. Any unnecessary steps are skipped.\n\n**Examples of validation and simplification:**\n\n- A self-intersecting polygon is provided: \n    - An error is displayed.\n- A single outline is provided, consisting of 1000 points:\n    - A simplified version of the same outline is used, consisting of fewer than 400 points.\n- Multiple geometries are provided, all of them overlapping at least in part:\n    - A single outline is returned, representing the outline of all the shapes combined.\n- Multiple geometries are provided, at least some of them entirely non-overlapping:\n    - A single outline is returned, representing the convex hull of all the shapes together.\n\n### Temporal Parameters\n- <span style=\"color: #236192; font-size: 20px;\">processingDate</span>\n    - Limit results to records that have been processed at ASF since a given date and/or time.\n    - Example:\n        - processingDate='2017-01-01T00:00:00UTC'\n\n- <span style=\"color: #236192; font-size: 20px;\">start</span>\n    - Date of data acquisition. Can be used in combination with 'end'. You may enter natural language dates, or a date and/or time stamp. All times are in UTC.\n    - Example:\n        - start='May 30, 2019'\n        - start='yesterday'\n        - start='2010-10-30T11:59:59Z'\n        - start='1 week ago', end='now'\n\n- <span style=\"color: #236192; font-size: 20px;\">end</span>\n    - Date of data acquisition. Can be used in combination with 'start'. You may enter natural language dates, or a date and/or time stamp. All times are in UTC.\n        - end='May 30, 2018'\n        - end='today'\n        - end='2021-04-30T11:59:59Z'\n        - start='1 week ago', end='now'\n\n- <span style=\"color: #236192; font-size: 20px;\">season</span>\n    - Start and end day of year for desired seasonal range. This keyword may be used in conjunction with start/end to specify a seasonal range within an overall date range. Values are based on the Julian calendar. You must specify both a season start and end date.\n    - Example:\n        - season=[1, 31]\n        - season=[45, 67]\n        - season=[360, 10]\n    - Values:\n        - 1 through 365\n\n### Baseline Parameters\n- <span style=\"color: #236192; font-size: 20px;\">stack_from_id</span>\n    - Input the scene name for which you wish to see baseline results.\n    - stack_from_id may not be used in conjuction with other keywords.\n    - Example: \n        - stack_from_id('S1A_IW_SLC__1SDV_20220215T225119_20220215T225146_041930_04FE2E_9252-SLC')\n    - See the [Jupyter notebook](https://github.com/asfadmin/Discovery-asf_search/blob/master/examples/4-Baseline_Search.ipynb) for usage examples, as well as best practices.\n\n### Results Parameters\n- <span style=\"color: #236192; font-size: 20px;\">maxResults</span>\n    - Maximum number of data records to return.\n    - Example:\n        - maxResults=10\n",
  "TOOLS_1": "# Search API Tools\n\nSearches may be executed in a variety of ways, depending on your needs. On this page, you will find syntax & character encoding tips, and further information on some of the ways to run Search API queries.\n\n## Syntax and Character Encoding\n\n**Syntax tips**\n\n1. A \"?\" separates the endpoint URL from the keywords.\n2. Keywords are joined by a \"&\". Some operating systems or programs may require a \"\\&\"\n3. There may not be any spaces or parentheses in the URL string. See below for how to encode these characters.\n\n**Character Encoding:**\n\n>space\n>\n>replace with '%20'. Use '+'  in keyword values\n>\n>(\n>\n>replace with '%28'\n>\n>)\n>\n>replace with '%29'\n>\n\nFor a complete list of URL codes, please see [URL Encoding Reference](https://www.w3schools.com/tags/ref_urlencode.asp).\n\n**Escaping Characters**\n\nIf you are running Search API queries via command line, you may need to escape characters. Escaping a character tells the command line interface to interpret the character literally. Some characters that need to be escaped include spaces and ampersands (&).\n\nFor more information on escaping characters, please see the [Bash Scripting Guide](https://tldp.org/LDP/abs/html/escapingsection.html). For Windows users, more information can be found [here](https://ss64.com/nt/syntax-esc.html).\n\n## Program Details\n\nYou may use a program to assist you with Search API queries. This section will provide some details on a few of the programs you can use to write & run Search API queries and some example commands for each.\n\n- [aria2](https://wiki.archlinux.org/title/aria2)\n- [Wget](https://www.gnu.org/software/wget/)\n- [cURL](https://curl.se/docs/manpage.html)\n\nBoth [Wget](http://wget.addictivecode.org/FrequentlyAskedQuestions.html?action=show&redirect=Faq#download) and [cURL](https://curl.se/) are often installed on Linux systems. cURL is part of the Mac OS, and Wget can be installed. Microsoft Windows OS does not come with either installed, but both can be downloaded. cURL is easier to set up on a Windows machine. [aria2](https://aria2.github.io/) can be installed on Windows, Mac, or Linux systems.\n\n### Examples using aria2\n\naria2c can be used to download results from the Search API with a single command. You will need to include your Earthdata username and password, all desired keywords & values, and ensure that output=metalink.\n\n**Aria2 — Linux/Mac Example - Download Known Scene**\n\n      aria2c --http-auth-challenge=true --http-user=CHANGE_ME --http-passwd='CHANGE_ME' \"https://api.daac.asf.alaska.edu/services/search/param?granule_list=S1A_EW_GRDM_1SDH_20151003T040339_20151003T040443_007983_00B2A6_DDE4&output=metalink\"\n\n**Aria2 — Windows Example - Download Known Scene**\n\n      aria2c --check-certificate=false --http-auth-challenge=true --http-user=CHANGE_ME --http-passwd=\"CHANGE_ME\" \"https://api.daac.asf.alaska.edu/services/search/param?granule_list=S1A_EW_GRDM_1SDH_20151003T040339_20151003T040443_007983_00B2A6_DDE4&output=metalink\"\n\n**Aria2 — Download Based on Platform and Time-Range Search**\n\n      aria2c --http-auth-challenge=true --http-user=CHANGE_ME --http-passwd='CHANGE_ME' \"https://api.daac.asf.alaska.edu/services/search/param?platform=Sentinel-1A&intersectsWith=point(-122.425 37.77)&start=2016-07-01T00:00:00&output=metalink\"\n\nYou can store your login credentials in a config file, instead of including them in every download command.\n\n**aria2 - Linux/Mac Example — Create and use a configuration file**\n\n      echo 'http-user=CHANGE_ME' >> aria2.conf\n      echo 'http-passwd=CHANGE_ME' >> aria2.conf\n      chmod 600 aria2.conf\n\n      aria2c --conf-path=aria2.conf --http-auth-challenge=true \"https://api.daac.asf.alaska.edu/services/search/param?granule_list=S1A_EW_GRDM_1SDH_20151003T040339_20151003T040443_007983_00B2A6_DDE4&output=metalink\"\n\nAdditional aria2 options are available in the [aria2 manual](http://aria2.sourceforge.net/manual/en/html/aria2c.html).\n\nRefer to the complete documentation on [configuration files for aria2](https://aria2.github.io/manual/en/html/aria2c.html#aria2-conf).\n\n### Examples using Wget\n\nOnce you have the download URL, you can download files individually using Wget. You can find the download URL for your desired results by first using outputs csv, json, metalink, or geojson.\n\n**Wget - Linux/Mac Example — Download a file**\n\n      wget -c --http-user=CHANGE_ME --http-password='CHANGE_ME' \"https://datapool.asf.alaska.edu/GRD_MD/SA/S1A_EW_GRDM_1SDH_20151003T040339_20151003T040443_007983_00B2A6_DDE4.zip\"\n\n**Wget - Windows Example — Download a file**\n\n      wget --check-certificate=off -c --http-user=CHANGE_ME --http-password=\"CHANGE_ME\" \"https://datapool.asf.alaska.edu/GRD_MD/SA/S1A_EW_GRDM_1SDH_20151003T040339_20151003T040443_007983_00B2A6_DDE4.zip\"\n\n      wget -c --http-user=CHANGE_ME --http-password=\"CHANGE_ME\" \"https://datapool.asf.alaska.edu/GRD_MD/SA/S1A_EW_GRDM_1SDH_20151003T040339_20151003T040443_007983_00B2A6_DDE4.zip\"\n\nYou can store your login credentials in a config file, instead of including them in every download command.\n\n**Wget - Linux/Mac Example — Create and use a configuration file**\n\n      echo 'http_user=CHANGE_ME' >> wget.conf\n      echo 'http_password=CHANGE_ME' >> wget.conf\n      chmod 600 wget.conf\n\n      export WGETRC=\"wget.conf\"\n      wget -c \"https://datapool.asf.alaska.edu/GRD_MD/SA/S1A_EW_GRDM_1SDH_20151003T040339_20151003T040443_007983_00B2A6_DDE4.zip\"\n\nYou can also send results to a file on your PC\n\n**Example — query results sent to a metalink file**\n\n      wget -O myfilename.metalink https://api.daac.asf.alaska.edu/services/search/param?intersectsWith=point%28-119.543+37.925%29\\&platform=ALOS\\&output=metalink\n\n**Visualize Example - Mac/Linux**\n\n      wget -O myfilename.kml https://api.daac.asf.alaska.edu/services/search/param?granule_list=ALPSRP074606580,ALPSRP077086550\\&output=KML\n\n**Download Example - Windows**\n\n      wget -c -O myfilename.metalink https://api.daac.asf.alaska.edu/services/search/param?granule_list=ALPSRP074606580,ALPSRP077086550\\&output=METALINK\n\nAdditional Wget options are available in the [GNU Wget Manual](https://www.gnu.org/software/wget/manual/wget.html).\n\nRefer to the complete documentation on [configuration files for Wget](https://www.gnu.org/software/wget/manual/html_node/Startup-File.html#Startup-File).\n\n### Examples using cURL\n\n**cURL - Mac/Linux Example**\n\n      curl https://api.daac.asf.alaska.edu/services/search/param?platform=R1\\&absoluteOrbit=25234\\&output=CSV\n\n**cURL - Windows Example**\n\nNote: Copy/pasting quotation marks sometimes causes errors. Delete and re-type the quotes after pasting.\n\n      curl \"https://api.daac.asf.alaska.edu/services/search/param?platform=R1&absoluteOrbit=25234&output=CSV\" > myfilename.csv\n\nYou can also send results to a file on your PC\n\n**Mac/Linux Example — query results sent to a metalink file**\n\n      curl https://api.daac.asf.alaska.edu/services/search/param?granule_list=ALPSRP074606580,ALPSRP021910740,ALPSRP085800750 >myfilename.metalink\n\n**Windows Example — query results sent to a metalink file**\n\n      curl \"https://api.daac.asf.alaska.edu/services/search/param?granule_list=ALPSRP074606580,ALPSRP021910740,ALPSRP085800750\" > myfilename.metalink\n\n**Search Example - Mac/Linux**\n\n      curl https://api.daac.asf.alaska.edu/services/search/param?platform=r1\\&asfframe=300\\&output=CSV > myfilename.csv\n\n**Search Example - Windows**\n\n      curl  \"https://api.daac.asf.alaska.edu/services/search/param?platform=r1&asfframe=300&output=CSV\" > myfilename.csv\n\n**Visualize Example - Windows**\n\n      curl \"https://api.daac.asf.alaska.edu/services/search/param?granule_list=ALPSRP074606580,ALPSRP077086550&output=KML\" >myfilename.kml\n\n**Download Example - Windows**\n\n      curl -L \"https://api.daac.asf.alaska.edu/services/search/param?granule_list=ALPSRP074606580,ALPSRP077086550&output=METALINK\" >myfilename.metalink\n\n## POST Requests\nSome keywords and endpoints will accept a POST request. The POST examples below are using cURL.\n\n**POST Example - WKT output from file**\n\n      curl -X POST -F 'files=@/path/to/file.geojson' 'https://api.daac.asf.alaska.edu/services/utils/files_to_wkt'\n\n**POST Examples - intersectsWith Keyword**\n\n      curl -X POST -F 'intersectsWith=LINESTRING(-97.1191 26.4312,-95.5371 29.1522,-83.7598 29.993,-81.5625 25.4036)' 'https://api.daac.asf.alaska.edu/services/search/param'\n\nYou can add additional parameters to your POST request with the -F argument for each desired parameter.\n\n      curl -X POST -F 'platform=S1' -F 'output=geojson' -F 'maxresults=10' -F 'intersectsWith=POINT(-102.4805 38.7541)' 'https://api.daac.asf.alaska.edu/services/search/param'\n\nFor further reading, see [POST requests](https://en.wikipedia.org/wiki/POST_(HTTP))\n\n## Web Browser\n\nYou may run the Search API queries directly in a web browser of your choice. Simply copy and paste the query into a web browser. Any errors will be returned in JSON format.\n\nYou will need to use URL encoding for spaces and parentheses. Please refer to the Character Encoding section or see [URL Encoding Reference](https://www.w3schools.com/tags/ref_urlencode.asp) for more details.\n\n",
  "TROUBLESHOOTING_1": "# Search API Troubleshooting\n\nIf you are troubleshooting Search API queries, consider using asf_search. asf_search is a Python module for performing searches of the ASF catalog. More information can be found [here](/asf_search/basics).\n\n**Trouble Area: Query returns HTTP 429 with error message**\n\n- Reason: Query returns HTTP 429 with error message \"Rate limited, please reduce your request rate to 250/minute or less\"\n- Remedy: There is a rate limitation on the search endpoint. Refer to [Rate limitations](/api/cookbook/#rate-limitation-on-search-endpoint) for tips on how to construct your queries. \n\n**Trouble Area: Windows cURL “unrecognized protocol”**\n\n- Reason: Invisible double quotes inserted when copy/pasting examples\n- Remedy: Delete the visible quotes, which will delete the invisible quotes. Then retype quotes.\n\n**Trouble Area: Download fails with “401 Unauthorized” or “Authorization failed”**\n\n- Reason: Missing or invalid Earthdata username/password\n- Remedy: Check that you are correctly including your Earthdata username and password in your download command or config file.\n\n**Trouble Area: Download fails with “401 Unauthorized” or “Authorization failed”**\n\n- Reason: Special characters in Earthdata password\n- Remedy: Passwords with special characters will need to be inside quotes.\n\n**Trouble Area: Can’t authenticate**\n\n- Reason: Missing study area or EULA\n- Remedy: Log in to Earthdata and ensure your study area is set, and you have agreed to all necessary End-User License Agreements.\n\n**Trouble Area: Search API request with ‘+’ in it fails**\n\n- Reason: Some keyword values could contain spaces.\n- Remedy: Try replacing the ‘+’ with ‘%2B’. For further details, refer to Character Encoding on the [Tools page](/api/tools).\n\n**Trouble Area: Search API request fails**\n\n- Reason: https is required\n- Remedy: Make sure you are using https, not http.\n\n**Trouble Area: Search API request hangs, fails, or returns an error**\n\n- Reason: Your URL may include spaces or special characters.\n- Remedy: Refer to Character Encoding on the [Tools page](/api/tools) and ensure you are encoding spaces and special characters correctly.\n\n**Trouble Area: Search API returns Validation Error**\n\n- Reason: The reason for the validation error is included in the returned error message.\n- Remedy: Refine your keywords and values as needed. If you are unsure why you received the validation error, you may contact ASF using the info below.\n\n**Trouble Area: Search API query does not return expected number of results**\n\n- Reason: There is a 15 minute time limit on running Search API queries.\n- Remedy: First, try the same query with \"output=count\". If the count is high, consider narrowing your search by using more keywords, or by using keyword “maxResults” to limit it. You may also try shortening the date range to split your search into a series of smaller searches.\n\n**Trouble Area: Search API query with \"product_list\" keyword returns no results**\n\n- Reason: Other keywords may be competing with the product_list value(s).\n- Remedy: Try removing other keywords from your query. You may also try \"output=count\" to see how many results your query should return.\n\n**Trouble Area: Selected output format does not include needed fields**\n\n- Reason: Some output formats include different fields.\n- Remedy: GeoJSON is the preferred default format. If a required field is not included, please contact ASF using the info below or reach the team directly at <uaf-asf-discovery@alaska.edu>\n\n<!-- - Trouble Area: Certificate rejected\n\t- Reason: Third-party certificates out of date, a problem for https searches\n\t- Remedy: Use http OR disable certificate checks.\n\t\t- [curl](https://curl.se/docs/manpage.html) –insecure\n\t\t- [wget](https://www.gnu.org/software/wget/) –no-check-certificate\n -->\n",
  "VERTEX_MANUAL_1": "# Vertex Getting Started User Guide\n\n- If you do not already have one, create a free **[Earthdata Login account](https://urs.earthdata.nasa.gov/users/new)**.\n- Go to **[Vertex](https://search.asf.alaska.edu)**\n\t- Log in by clicking the **Sign in** icon in the top right of the window. Use your Earthdata Login username and password.\n\t![type:video](https://www.youtube.com/embed/j_Db_ipKLos)\n- Search Type allows you to choose between all available search types.\n\n## Language Options\n\nIn the top right menu, next to the **Sign In** icon, there are language control options. Vertex currently offers English and Spanish. If your browser is set to one of the available languages, Vertex will default to that language. You may click the button and select your desired language from the drop down list. You may also set a default language in your **Preferences**. \n\n## *Geographic* Search Options\n\n![type:video](https://www.youtube.com/embed/JovQ-rG9ZJE)\n\n- In the top left corner of the map, there are buttons that allow you to change your **map projection**, **zoom**, and **map view**.\n\t- By default, the map is in equatorial projection. You may click **Map View** and select **Arctic map view** or **Antarctic map view** to change your map projection. Click **Equatorial map view** to switch back to the equatorial projection.\n\t- You may click the **Zoom In** or **Zoom Out** icons to adjust your zoom.\n\t- The default map layer is satellite. You may click the **Layers** button and select **Satellite View** or **Street View** to switch your map layer.\n\t\t- You may click **Overview Map** to add an overview map in the top right corner of the map. Click it again to turn off the overview map.\n\t\t- You may click **Gridlines** to add a graticule overlay to the map. Click it again to turn off the overlay. *Note*: This is currently only available in the equatorial map view.\n\t- You may click **Opacity** and adjust the slider as desired to change the opacity of browse images displayed on the map.\n- Navigate to your area of interest by dragging the map while holding down the left mouse button.\n- By default, the map-drawing tool is a bounding box. Click on the map once to specify the starting corner, move the mouse, then click again to finish the box. Additional drawing tool options are available in the toolbar at the top of the screen, including *point*, *linestring*, and *polygon* options.\n\t- **Point** allows you to define an area of interest by clicking on the map to place a point.\n\t- **Line** allows you to define an area of interest over a series of line segments by clicking on the map multiple times. Double-click to stop adding segments.\n\t- **Polygon** allows you to define an area of interest over an arbitrary polygon. You will receive an error message at the bottom of the window if there was a problem with the polygon (self-intersecting, reversed polygon winding order, etc.).\n\t- **Box** allows you to define an area of interest over a lat/long-aligned bounding box by clicking once to set one corner, and again to set the opposite corner.\n\t- Once a shape has been drawn, select the **Edit current area of interest** icon on the toolbar to move, add, and delete points. Select the **Draw new area of interest** icon to create a new AOI.\n\t- Clicking **Upload Goespatial File** brings up the Area of Interest dialog window. You may enter a WKT string, upload a geospatial file, or enter a location.\n- **Dataset** enables you to choose the dataset of interest.\n\t- If you need more information about a particular dataset, click on the appropriate question mark icon in the Dataset selector.\n- **Filters...** enables you to further refine your search\n\n### Area of Interest Options\n\n- **Area of Interest** gives you the option of entering a set of geographic coordinates, importing an area of interest as a geospatial file, or searching for a location. Click on the down arrow next to **Area of Interest** in the top menu.\n\t- An area of interest may be defined by a set of coordinates entered in the **Area of Interest WKT** window.\n\t\t- Coordinates should be entered as decimal degrees in *well-known text* (WKT) format. Coordinates entered as a comma-separated long/lat string (e.g. -97.38,36.46,-53.44,36.46...) will be automatically converted by Vertex to WKT format.\n\t- To upload a geospatial file, click **Select Files** and navigate to a folder on your computer, or drag and drop files into the box. *GeoJSON*, *shapefiles*, and *KML* files are supported provided they are in a latitude/longitude-based coordinate system, such as WGS84.\n\t\t- When importing a *GeoJSON* file, all geometries in the file will be included. If multiple geometries are found, a convex hull will be used to represent them in the search.\n\t\t- *Shapefiles* can be either a single *.shp* file, multiple shapefile components (*.shp, .shx, .dbf*), or a *zip* file containing one or more shapefile components. At a minimum, the *.shp* component must be included in all cases.\n\t- To enter a location, click the **Search for a Location** field, and start typing the name of the location. Select your desired location from the drop down list. \n\t\t- Once you have selected a location, it will be geocoded into WKT format coordinates.\n\t- You can save the coordinates of a search so they can be used to exactly recreate an area of interest in later searches.\n\t\t- Once the **Area of Interest** has been set, a *Copy to clipboard* icon will appear. Click on the icon and paste the coordinates into a new search or to a text file for later use.\n\t\t- Note: See the section **Other Vertex Options** for additional ways of saving searches.\n\t- At any time you can clear your search area by clicking on the **Clear** button.\n\n#### Shape Validation\nIf the AOI specified is its own Minimum Bounding Rectangle (MBR) in a mercator projection, the search results returned will instersect with the AOI in a mercator projection, regardless of width. This remains the case even if the international dateline is crossed within the AOI.\n\nIn order for an AOI to be considered its own MBR, it must meet the following criteria:\n\n  - Each vertex shares a latitude or longitude with its neighbors\n  - East/West points share longitude\n  - North/South points share latitude\n\nAOIs that do not fit this criteria will have their points connected along [great circles](https://en.wikipedia.org/wiki/Great_circle).\n\nIn addition, all AOIs are validated, and then simplified as needed. The process for this is:\n\n  1. Validate the input AOI. If it is not valid, an error is displayed.\n  2. Merge overlapping shapes.\n  3. Convex hull.\n  4. Any out-of-range index values are handled by clamping and wrapping them to the valid range of values.\n  5. Simplify points based on proximity threshold. The target is fewer than 400 points.\n\nEach of these steps is performed only when necessary to get the AOI to a single outline with fewer than 400 points. Any unnecessary steps are skipped.\n\n**Examples of validation and simplification:**\n\n- A self-intersecting polygon is provided:\n\t- An error is displayed.\n- A single outline is provided, consisting of 1000 points:\n\t- A simplified version of the same outline is used, consisting of fewer than 400 points.\n- Multiple geometries are provided, all of them overlapping at least in part:\n\t- A single outline is returned, representing the outline of all the shapes combined.\n- Multiple geometries are provided, at least some of them entirely non-overlapping:\n\t- A single outline is returned, representing the convex hull of all the shapes together.\n\n### Date Filters\n\n- **Date Filters** Search dates are optional, so they default to empty.  If you are searching for specific dates, you can define the date range further in the **Start Date** and **End Date** fields. The date picker will automatically constrain your selection to a valid range for the selected dataset.\n\t- *Note*: this information may also be found by clicking on the question mark icon for a dataset.\n\t- **Seasonal Search** allows constraining the search to certain annual periods within an overall range of dates.  Click the Seasonal Search toggle and additional options will appear, allowing you to enter an overall date range (*Start Date/End Date*) and the seasonal range (*Season Start Day/Season End Day*).\n\n### Additional Filters\n\n![type:video](https://www.youtube.com/embed/Vd9eDL9KVK4)\n\n- **Additional Filters** allow for additional parameters to be applied to narrow your search and reduce the number of results. Not all filters will be available for all datasets.\n\t- **File Type** – Limit the search to specific types of files. Multiple selections allowed.\n\t- **Beam Mode** – Limit the search to specific beam modes. Multiple selections allowed.\n\t- **Polarization** – Limit the search to specific polarizations. Multiple selections allowed.\n\t- **Direction** – Limit the search to a specific orbit direction.\n\t- **Subtype** – Limit the search to a specific mission spacecraft.\n\t- **Group ID** – Limit the search to a specific group ID.\n\t- **Burst ID** – Limit the search to a specific burst ID. Multiple burst IDs allowed.\n\n\n### Path and Frame Filters\n\n- **Path and Frame Filters** are available for select datasets. You may enter a single path or frame, or a range. Due to inconsistent Sentinel-1 framing, we recommend searching for a frame of interest by ±1-2 frames.\n- The maximum number of results is displayed below the **SEARCH** button. Click the **down arrow** to choose your preferred maximum results.\n\t- You may click **API URL...** in order to generate the API URL matching your current search parameters. This will open a new window.\n\t\t- **Amount** allows you to set the maximum results.\n\t\t- **Format** allows you to choose your preferred output format.\n\t\t- The **Copy** icon next to the URL will copy the URL. It can be pasted into a browser search bar to perform the API search, or pasted into a document and saved.\n\t\t- **API Docs** will send you to the [API Documentation](https://asf.alaska.edu/api/).\n\t\t- **Download Results** will download the results in the specified output format.\n- Once all parameters have been chosen, click **SEARCH**. Search results will appear in the footer area of the Vertex window, and on the map.\n\t- *Note*: The number of files that are predicted to match the current search parameters is displayed under the SEARCH button. If there are no predicted matches, the search button will be greyed out and display NO RESULTS.\n\n## *List* Search Options\n\n![type:video](https://www.youtube.com/embed/oetqxZkqVZM)\n\n- Selecting **List Search** opens the *List Search* window and allows you to enter a list of scenes or file names.\n\t- **Scene** allows searching for specific scene names (granule names), and the results will include any files that are part of those scenes.\n\t- **File** allows searching for specific file names (product names), and the results will only include exactly those files.\n- **Edit List** opens the *List Search* window so you can make changes to your list\n- Once all parameters have been chosen, click **SEARCH**. Search results will appear in the footer area of your browser window, and on the map.\n\t- *Note*: The number of files that are predicted to match the current search parameters is displayed under the SEARCH button. If there are no predicted matches, the search button will be greyed out and will display NO RESULTS.\n\n### List Search File Import\nYou may **drag and drop files** into the box provided on the **Scene** or **File** tabs. Each tab lists the file types accepted at the bottom. Vertex will parse the scene or file names from your uploaded file.\n\n- *Note*: Each file type requires a specific format. Files exported from Vertex will have the correct format.\n\n- **CSV** requires a column labeled \"Granule Name\" for a scene list search. It requires an additonal \"Processing Level\" column for a file list search.\n- **GeoJSON** requires a field labeled \"granuleName\" for scene list search. It requires a field labeled \"fileID\" for file list search.\n- **Metalink** requires a structure formatted as\n```\n<metalink>\n    <files>\n        <file name=\"[Scene-Name.zip]\"></file>\n        <file name =\"...\n        ...</file>\n    </files>\n</metalink>\n```\n\n- **KML** requires a structure formatted as\n```\n<kml>\n    <Document>\n        <Placemark>\n            <name>[Scene Name]</name>\n        </Placemark>\n    </Document>\n</kml>\n```\n\n## *Baseline* Search Options\n\n![type:video](https://www.youtube.com/embed/Xp5bgvi2pEM)\n\n- Selecting **Baseline Search** provides a space to enter the name of a Reference Scene, and will then search for all secondary scenes that match the coverage area of the Reference.\n\t- *Note*: If there are no matching scenes, the RESULTS button will be greyed out and will display NO RESULTS.\n- Once a Reference Scene has been entered, click **SEARCH**. Search results will appear under the map. Clicking on the *Zoom to results* icon at the top of the left results column will display the location of the stack of scenes on the map.\n- The graph displays the Temporal and Perpendicular (spatial) relationship of the secondary scenes to the Reference.\n- Clicking on **Baseline Criteria...** above the graph will open the *Baseline Search* window. Using the sliders, the Temporal and Perpendicular extents can be adjusted to limit the number of secondary scenes displayed in the results.\n- For further information on **Baseline**, please see the [Baseline documentation](/vertex/baseline).\n\n## *SBAS* Search Options\n\n![type:video](https://www.youtube.com/embed/bQPdtuobdcg)\n\n- Selecting **SBAS Search** provides a space to enter the name of a Reference Scene, and will search for all secondary scenes that match the coverage area of the Reference. It is an alternate method used for Interferometric SAR (InSAR) processing, similar to Baseline.\n\t- *Note*: If there are no matching scenes, the RESULTS button will be greyed out and will display NO RESULTS.\n- Once a Reference Scene has been entered, click **SEARCH**. Search results will appear under the map. Clicking on the *Zoom to results* icon at the top of the left results column will display the location of the stack of scenes on the map.\n- The chart displays the Temporal and Perpendicular (spatial) relationship of the secondary scenes to the Reference.\n\t- **Zoom In** and **Zoom Out** buttons are available above the chart.\n\t- The **Zoom to Fit** button ensures that all pairs are visible on the chart.\n\t- The **Custom Pair** buttons allow you to add or delete a custom pair.\n\t- The **SBAS Criteria...** button allows you to specify additional criteria to refine your results, such as start and end dates, seasonal date settings, and latitudinal overlap threshold settings.\n- For further information on **SBAS**, please see the [SBAS documentation](/vertex/sbas).\n\n## *Event* Search Options\n\n- Selecting **Event** allows you to view and search the products created for hazard monitoring.\n- **Event Search** allows you to enter an event name. You may enter the full name or a partial string.\n- **Event Types** allows you to filter which types of events you wish to see. Currently, there are earthquake and volcano events.\n- **Start Date** and **End Date** allow you to specify a date range for events.\n- Additional options may be found under **Filters**.\n\t- You may toggle the **Active Events Only** switch to display only active events. The default is to display all events, including inactive events.\n\t- You may adjust the **Magnitude** slider to filter earthquakes by your desired magnitude range. *Note:* This filter applies only to earthquake events. If your search includes volcanoes, these will continue to be displayed in your search results.\n- For further information on **Event** search, please see the [Event Search documentation](/vertex/events).\n\n## *On Demand Products* Search Options\n\n- Selecting **On Demand Products** allows you to view your submitted On Demand jobs. *Note*: You must be signed in to access this. If you are not signed in, this search option will be greyed out and you will not be able to select it.\n- **Project Name** allows you to limit your search to a specific project name. As you start typing, auto-complete options will become available with the project names you have previously used.\n- **Date Filters** Search dates are optional, so they default to empty.  If you are searching for specific dates, you can define the date range further in the **Start Date** and **End Date** fields. *Note*: These dates filter by the scene date, not the date it was processed.\n- **Product/Source Scene** allows you to enter the product name or source scene name to limit your search. This field will also accept a partial string from either the product or source scene in lieu of the full name.\n- **Job Status** allows you to limit your search to specific statuses. Multiple selections allowed.\n- *Note*: Jobs expire 14 days after you submit them. Expired products still appear in search results, however, you may no longer download or add them to your cart. You can easily identify your expired products by the **Expired** tag next to the product name.\n- For further information on **On Demand Products**, please see the [documentation](https://hyp3-docs.asf.alaska.edu/).\n\n## *Derived Datasets* Search Options\n\n- Selecting **Derived Datasets** allows you to view and download products from ASF's catalog of datasets.\n- Each dataset listed includes a short description.\n- Click **More Info** to view more information about the dataset.\n- Click **Download** to view and download available products for your chosen dataset. *Note*: The download link will open in a new browser window.\n- For further information on **Derived Datasets**, please see the [Derived Datasets documentation](/vertex/derived_datasets/).\n\n## Search Results\n\n![type:video](https://www.youtube.com/embed/wp8Xt_Y4T84)\n\n- In Vertex, a **scene** is considered to be a package containing all **files**, or products, that are related to a specific location and time.\n\t- *For example*, the column on the left of the Results panel displays the scenes returned from a search. The column on the right displays the file contents of each scene.\n- The maximum number of files that a search will return is displayed under the SEARCH button.\n\t- This number can be adjusted by clicking on the down arrow.\n\t- The total number of files that match the search parameters is also displayed.\n- The Results header bar.\n\t- The **Zoom** button will zoom-in to the location of all scenes on the map.\n\t- The **Queue** button will add all scenes to the download queue.\n\t- The **On Demand** button will allow you to choose which eligible scenes to add to the On Demand Queue for further processing.\n\t- The **Raw** button will show or hide raw files. *Note*: This button is applicable for Sentinel-1 scenes only.\n\t- The **Export** button will allow you to export data or metadata for all scenes in the results.\n\t- The **Expired** button will show or hide expired On Demand files. *Note*: This button is only available in the **On Demand Products** search type.\n\t- *Note*: Not all buttons are available on all search types.\n- The **Scenes** column (left).\n\t- Click on the cart icon next to a scene name to add all the scene’s files to the download queue. The cart changes appearance when this is done.\n\t- Click on the zoom icon next to a scene name to zoom-in to the scene’s location on the map.\n- To view more information about a scene, click on the scene in the left column and the **Scene Detail** and **Files** columns will populate.\n\t- The **Scene Detail** column (center) provides a more detailed description of the scene, including *Start Date/Time*, *Beam Mode*, *Path*, *Frame*, *Flight Direction*, *Polarization*, *Absolute Orbit*, and a browse image (if available). Not all scenes will have all the extra information.\n\t\t- The **Baseline Tool** button opens the ASF Baseline Tool, which is used for creating InSAR stacks.\n\t\t- The **SBAS Tool** button opens the ASF SBAS Tool, which is another method of creating InSAR stacks.\n\t\t- The **More Like This** button creates a search based on the selected scene’s path and frame.\n\t\t![type:video](https://www.youtube.com/embed/h7vmrcpMd60)\n\t\t- The **Source Data** button creates a search for the source Sentinel-1 scene based on the Opera product’s Group ID. *Note*: This button is only available for Opera-S1 search results.\n\t\t- The **Citation** button opens a new window with citation guidance for published works using data, imagery, or tools accessed through ASF.\n\t\t- **Download this Image** downloads the browse image.\n\t\t- The eye icon labeled **Open in Image Viewer** opens a larger browse viewer window.\n\t\t\t- In the browse viewer, **zoom** using the **+** or **-** buttons. You may also zoom and pan using the mouse.\n\t\t\t- Click or scroll through the thumbnails at the bottom to see other browse images for scenes returned by your search.\n\t\t\t- By default, the **Only display scenes with a browse image** box is checked. You may uncheck this to see all scenes returned by your search. Scenes without a browse image will show a thumbnail listing *No Browse Available*.\n\t\t\t- The scene metadata is listed on the right side of the browse viewer window.\n\t- The **Files** column (right) displays a list of files available for the currently selected scene. You may download files immediately or add them to your download queue by clicking on the appropriate icon.\n\t\t- Clicking on the right arrow in front a file (product) name will expand the file to show the ancillary files included. These files may be downloaded individually or added to the download queue.\n\t\t\t- You must be signed in to Vertex for this feature to work.\n\t\t\t- This feature is not available for all datasets.\n\n## On Demand Queue\n\n![type:video](https://www.youtube.com/embed/AxhYMBzycuY)\n\n- Clicking on the **three boxes** icon in the header, labeled **On Demand**, will display a drop down list of options.\n- **On Demand Queue** will open the On Demand queue.\n\t- The different jobs types in your queue are separated by tabs along the top of the queue. The job types currently available are **RTC GAMMA**, **InSAR GAMMA**, and **autoRIFT**. You may click on a tab to select it. The selected tab is highlighted.\n\t- For **RTC GAMMA** and **InSAR GAMMA** jobs, there are additional processing options available.  The options you select will apply to all files of that job type in your queue.\n\t\t- You may hover over each option to display a tool tip with details on the option.\n\t- Choose your desired sorting with the **Sort Criteria** and **Sort Order** drop down boxes.\n\t\t- Under **Sort Criteria**, you may choose to sort files by *Start Date* of the file, or by *Date Added* to the queue.\n\t\t- Under **Sort Order**, you may choose to sort files by *Latest* or most recent, or by *Oldest*.\n\t- The list of files you have added to your queue is listed below the options. The X allows you to remove any files you wish from the queue.\n\t-  **Clear** will list some options for clearing files from your queue. You can choose to clear an individual tab, or you can choose **Clear All Processing Types** to clear all files from the queue. If you choose to clear all files, the option *Restore* will be displayed to allow you to undo this action.\n\t- The number of jobs remaining is displayed at the bottom of the queue. There are 1,000 jobs allotted to each user per month. If you have too many jobs in your queue, a message stating the number of extra jobs will be displayed at the top of the queue. The **Sumbit** button will be greyed out.\n\t- When you are satisfied with your selections, click **Submit Jobs** at the bottom. This will display the Review Submission window.\n\t\t- The **Project Name** field allows you to create a name for the files you want to submit for processing. The character limit is 20. This field is optional.\n\t\t- You may select or deselect the checkboxes to submit only the job types you wish.\n\t\t- Select **Cancel** to return to the queue without submitting any files for processing.\n\t\t- Click **Submit** to submit your jobs. *Note:* The Submit button will list the number of jobs you are submitting.\n\t\t- If there are any errors, such as missing DEM coverage, an error message will display.\n- **Submitted Products** will switch to On Demand Products search type and will display your submitted products.\n- **On Demand (HyP3) Docs** will send you to the [On Demand documentation](https://hyp3-docs.asf.alaska.edu/)\n- *Note*: You must be signed in to see your Submitted Products and to submit jobs from the On Demand Queue.\n\n## Downloads Queue\n\n![type:video](https://www.youtube.com/embed/cRjqbLNv4Aw)\n\nEnhanced download queue functionality is now available on Google Chrome browser. See [below](/vertex/manual/#google-chrome-browser) for more information.\n\n- Clicking on the **cart icon** in the header, labeled **Downloads**, will display the contents of your current download queue.\n\t- Within the download queue, the list of files you have selected to download is displayed with some basic information on each file, such as file type and size.\n\t\t- File IDs (names) can be copied with the **copy** icon.\n\t\t- Files can be individually downloaded with the **cloud** icon. You may also right click to save or copy the download URL.\n\t\t- Items can be removed from the queue with the **X**.\n\t- **Clear** will clear all files from the queue. The option *Restore* will be displayed to allow you to undo this action.\n\t- **Copy File IDs** will copy the file names of all files in the queue for use elsewhere. For example, this list could then be pasted into the *List Search* window.\n\t- **Copy URLs** will copy the download URLs of all files in the queue.\n\t- **Data Download** is used to download multiple products, with either the *Download Python Script (.py)* option or *Metalink (metalink)* file option.\n\t- **Metadata Download** is used to export the contents of the download queue to a *CSV*, *KML*, or *GeoJSON* file. The *KML* and *GeoJSON* files provided by this feature are compatible with the *Geographic Search Import* feature.\n\n### Google Chrome Browser\n\nEnhanced download queue functionality is available on Google Chrome browser. Please note, this improved functionality is not supported while using incognito mode.\n\n- Click on the **cart icon** in the header, labeled **Downloads** to open your download queue.\n\t- Next to each file, you may click the **cloud** icon to begin the download.\n\t\t- As the download begins, a progress indicator lists the percentage downloaded. Once the dowload has completed, the icon appears as a **check mark** to indicate the file has been downloaded.\n\t\t- While the file is downloading, you may click the progress indicator to stop the download.\n\t- Under **Data Download**, you may select **Download All**. This will download 3 files at a time until all products in your cart have been downloaded. The same progress indicators and checkmarks will be displayed to let you know the status of each download in your queue.\n\t\t- When you click **Download All**, a dialog box will appear:\n\t\t\t1. Navigate to the folder where you wish to save the files and click *Select*.\n\t\t\t2. Click *View Files* to allow the download to continue. \n\t\t\t3. Click *Save Changes* to save your download folder preferences. This will persist as long as the Vertex browser window remains open.\n\t- If you **Clear** the products in your queue, the download progress and completion indicators will reset. You may add the products to your queue again if desired.\n\t- *Note*: You must be signed in to download files. If you are not signed in, when you click to begin a download, you will be redirected to the sign in page first.\n\n## Other Vertex Options\n\n- In the top left corner of the map, there are buttons that allow you to change your **map projection**, **zoom**, and **map view**. *Note:* Available map controls vary by search type.\n![type:video](https://www.youtube.com/embed/qrUnsbZTVnA)\n\t- By default, the map is in equatorial projection. You may click **Map View** and select **Arctic map view** or **Antarctic map view** to change your map projection. Click **Equatorial map view** to switch back to the equatorial projection.\n\t- You may click the **Zoom In** or **Zoom Out** icons to adjust your zoom.\n\t- The default map layer is satellite. You may click the **Layers** button and select **Satellite View** or **Street View** to switch your map layer.\n\t\t- You may click **Overview Map** to add an overview map in the top right corner of the map. Click it again to turn off the overview map.\n\t\t- You may click **Gridlines** to add a graticule overlay to the map. Click it again to turn off the overlay. *Note*: This is currently only available in the equatorial map view.\n\t- You may click **Opacity** and adjust the slider as desired to change the opacity of browse images displayed on the map.\n- Click on the **down arrow** on the **Search**\n\t- **Clear Search** will clear all search parameters that have been set except for Search Type and Dataset.\n\t- **Saved Searches** opens a submenu.\n\t![type:video](https://www.youtube.com/embed/io4OQumWrJA)\n\t\t- **Save Search** allows you to name and save your current search.\n\t\t- **View Searches...** opens a list of searches that you have named and saved. Click on the magnifying glass icon to load the search settings.\n\t\t- **Search History...** opens a list of your 10 last searches that were not named and saved. Click on the magnifying glass icon to load the search settings.\n\t- **Saved Filters** opens a submenu.\n\t\t- **Save Filters** allows you to save your current filter set.\n\t\t- **View Filters...** allows you to view your saved filter sets. Click Apply Filters to apply them to your current search.\n\t- **Share Search** opens a submenu.\n\t\t- **Copy Search Link** will copy all the search parameters that have been set in the current search as a URL. The URL can then be pasted into a browser search bar to recreate the search exactly, or pasted into a document and saved to recreate the search later.\n\t\t- **Share With Email** will open a new email with the URL of the search to send to others.\n\t- **Help & Tutorials** provides both illustrated and video demonstrations on the basic steps for setting up a search and viewing the results.\n\t\t- *Note*: You must be signed in to Vertex for these options to be available.\n\t- **Export** opens a submenu.\n\t\t- **Export Python** will provide a Python code snippet to recreate the current search using the Python search module asf_search. It also provides a link to the asf_search documentation. \n\t\t- **Export API** will provide the API URL to recreate the current search using the SearchAPI. It also provides a link to the SearchAPI documentation. \n- Click **Help** for additional help options.\n\t- **Watch Our Tutorials** provides both illustrated and video demonstrations on how to use Vertex.\n\t- **Read Our User Guide** opens the Vertex documentation in a new tab.\n\t- **Read Our On Demand Guide** opens the On Demand documentation in a new tab.\n\t- **Find SAR Data Using ASF API** opens the SearchAPI documentation in a new tab.\n\t- **Learn More About ASF & SAR** opens the ASF website in a new tab.\n\t- **Statistics and GitHub Repository** provides links to our GitHub Vertex repository.\n- Click on the **Sign in** icon once you are signed in to display the user options.\n\t- **Saved Searches** opens a list of searches that you have named and saved. Click on the magnifying glass icon to load the search settings.\n\t- **Search History** opens a list of your 10 last searches that were not named and saved. Click on the magnifying glass icon to load the search settings.\n\t- **Saved Filters** opens a list of filters that you have saved. Click *Apply Filters* to apply the selected filter set to your search.\n\t- **Preferences** opens a window that allows you to set search preferences for language, theme, dataset, max results, map layer, and default filter presets. These preferences will be saved and applied to future searches.\n- *Note*: **Saved Searches**, **Saved Filters**, and **Search History** are available through both the Sign in menu and the Search button down arrow menu.\n- Click into the **Search all ASF** field on the grey header bar to perform a search. Inputs into this field will search across all ASF websites.\n\t- You may also click the **microphone** icon if you prefer to use voice search.\n\t- As you type or speak, the results of your search will be displayed in a list below the field. Clicking a result from the list will open a new browser tab.\n\t- You may click the **magnifying glass** icon to expand the search results. This will open in the same browser window. To close and return to Vertex, click the **X** near the top right of your screen."
}